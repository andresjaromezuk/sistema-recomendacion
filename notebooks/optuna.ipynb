{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  944249077\n",
       "1       1        2     1.0  944250228\n",
       "2       1        3     2.0  943230976\n",
       "3       1        4     5.0  944249077\n",
       "4       1        5     5.0  943228858"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('../data/ml-32m/ratings.csv')\n",
    "df_users = pd.read_csv('../data/ml-32m/users.csv')\n",
    "df_movies = pd.read_csv('../data/ml-32m/movies.csv')\n",
    "\n",
    "#df_movies.loc[df_movies['IMDB URL'].isna(), 'IMDB URL'] = ''\n",
    "\n",
    "u_unique = ratings.userId.unique()\n",
    "user2Idx = {o:i+1 for i,o in enumerate(u_unique)}\n",
    "\n",
    "m_unique = ratings.movieId.unique()\n",
    "movie2Idx = {o:i+1 for i,o in enumerate(m_unique)}\n",
    "\n",
    "ratings.userId = ratings.userId.apply(lambda x: user2Idx[x])\n",
    "\n",
    "ratings.movieId = ratings.movieId.apply(lambda x: movie2Idx[x])\n",
    "\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.0, 0.5, 3.5402706224956457)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ratings_train, ratings_val = train_test_split(ratings, test_size=0.2)\n",
    "n_users = int(ratings.userId.nunique())\n",
    "n_movies = int(ratings.movieId.nunique())\n",
    "n_users_train = int(ratings_train.userId.nunique())\n",
    "n_movies_train = int(ratings_train.movieId.nunique())\n",
    "print(n_users, n_movies, n_users_train, n_movies_train)\n",
    "max_rating = ratings_train['rating'].max()\n",
    "min_rating = ratings_train['rating'].min()\n",
    "av_rating = ratings_train['rating'].mean()\n",
    "max_rating, min_rating, av_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 23:06:53.320541: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, Dropout, Concatenate, Dense, Activation, Lambda\n",
    "from keras import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors_user = 5\n",
    "#mlflow.log_param(\"n_latent_factors_user\", n_latent_factors_user)\n",
    "n_latent_factors_movie = 5\n",
    "#mlflow.log_param(\"n_latent_factors_movie\", n_latent_factors_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "checkpointer = ModelCheckpoint(filepath='weights2.hdf5', verbose=1, save_best_only=True, monitor='val_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m \u001b[43mEarlyStopping\u001b[49m(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#mlflow.log_param(\"early_stopping_patience\", patience)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "patience = 5\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "#mlflow.log_param(\"early_stopping_patience\", patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',      # Métrica a monitorear (puede ser 'val_loss' o 'loss')\n",
    "    factor=0.5,              # Factor de reducción del learning rate (e.g., reduce a la mitad)\n",
    "    patience=5,              # Número de épocas sin mejora antes de reducir\n",
    "    min_lr=1e-6,             # Learning rate mínimo permitido\n",
    "    verbose=1                # Mostrar logs cuando se reduzca el LR\n",
    ")\n",
    "#mlflow.log_param(\"reduce_lr\", reduce_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K \n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.layers import Input, Embedding, Flatten, Dropout, Concatenate, Dense, Activation, Lambda\n",
    "    from keras import Model\n",
    "    from keras.regularizers import l2\n",
    "    from keras.optimizers import Adam\n",
    "    \n",
    "    \n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 5, 200)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 1e1, log=True)\n",
    "    activation = 'relu'\n",
    "    optimizer = 'adam'\n",
    "    dropout_1 = trial.suggest_float(\"dropout_1\", 0.1, 0.4, log=True)\n",
    "    dropout_2 = trial.suggest_float(\"dropout_2\", 0.1, 0.5, log=True)\n",
    "\n",
    "    ratings_train, ratings_val = train_test_split(ratings, test_size=0.2)\n",
    "    n_users = int(ratings.userId.nunique())\n",
    "    n_movies = int(ratings.movieId.nunique())\n",
    "    n_users_train = int(ratings_train.userId.nunique())\n",
    "    n_movies_train = int(ratings_train.movieId.nunique())\n",
    "    print(n_users, n_movies, n_users_train, n_movies_train)\n",
    "    max_rating = ratings_train['rating'].max()\n",
    "    min_rating = ratings_train['rating'].min()\n",
    "    av_rating = ratings_train['rating'].mean()\n",
    "    max_rating, min_rating, av_rating\n",
    "\n",
    "\n",
    "    movie_embedding_regularizer = 0.001\n",
    "    #mlflow.log_param(\"movie_embedding_regularizer_l2\", movie_embedding_regularizer)\n",
    "\n",
    "    movie_input = Input(shape=[1],name='Item')\n",
    "    movie_embedding = Embedding(n_movies + 1, n_latent_factors_movie, name='Movie-Embedding', embeddings_regularizer = l2(movie_embedding_regularizer))(movie_input)\n",
    "    movie_vec = Flatten(name='FlattenMovies')(movie_embedding)\n",
    "    movie_vec = Dropout(dropout_1)(movie_vec)\n",
    "\n",
    "    user_input = Input(shape=[1],name='User')\n",
    "    user_vec = Flatten(name='FlattenUsers')(Embedding(n_users + 1, \n",
    "    n_latent_factors_user,name='User-Embedding')(user_input))\n",
    "    user_vec = Dropout(dropout_1)(user_vec)\n",
    "\n",
    "    concat = Concatenate(name='Concat')([movie_vec, user_vec])\n",
    "    concat = Dropout(dropout_1)(concat)\n",
    "\n",
    "    x = Dense(hidden_units,name='FullyConnected-1', activation='relu')(concat)\n",
    "    x = Dropout(dropout_2)(x)\n",
    "    # x = Dense(50,name='FullyConnected-1', activation='relu')(concat)\n",
    "    # x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "    ## Se pueden sacar las siguientes dos lineas para no forzar a sigmoidea\n",
    "    x = Dense(1, activation='sigmoid',name='Activation')(x)\n",
    "    x = Lambda(lambda z: (max_rating - min_rating) * z + min_rating)(x)\n",
    "    ##\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='weights2.hdf5', verbose=1, save_best_only=True, monitor='val_root_mean_squared_error')\n",
    "\n",
    "    import keras.backend as K \n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n",
    "    model = Model([user_input, movie_input], x)\n",
    "    lr = 0.001\n",
    "    model.compile(Adam(learning_rate=learning_rate), 'mean_squared_error', metrics=[root_mean_squared_error])\n",
    "    #mlflow.log_param(\"lr\", lr)\n",
    "    batch_size = 320\n",
    "    epochs = 5\n",
    "    #mlflow.log_param(\"batch_size\", batch_size)\n",
    "    #mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "    history = model.fit([ratings_train.userId, ratings_train.movieId], \n",
    "                        ratings_train.rating, \n",
    "                        validation_data=([ratings_val.userId, ratings_val.movieId], ratings_val.rating), \n",
    "                        batch_size = batch_size,\n",
    "                        callbacks = [checkpointer],\n",
    "                        epochs=epochs, verbose=1)\n",
    "    val_loss, rmse = np.array(model.evaluate([ratings_val.userId, ratings_val.movieId], ratings_val.rating))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 20:27:29,289] A new study created in memory with name: no-name-4a116c67-5dd8-483a-9aed-0822cab0fc9f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 20:27:37.131553: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.1458 - root_mean_squared_error: 1.0637\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.05976, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 346s 4ms/step - loss: 1.1458 - root_mean_squared_error: 1.0637 - val_loss: 1.1321 - val_root_mean_squared_error: 1.0598\n",
      "Epoch 2/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.1344 - root_mean_squared_error: 1.0614\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.05976\n",
      "80001/80001 [==============================] - 983s 12ms/step - loss: 1.1344 - root_mean_squared_error: 1.0614 - val_loss: 1.1285 - val_root_mean_squared_error: 1.0602\n",
      "Epoch 3/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.1306 - root_mean_squared_error: 1.0603\n",
      "Epoch 3: val_root_mean_squared_error improved from 1.05976 to 1.05928, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 1701s 21ms/step - loss: 1.1306 - root_mean_squared_error: 1.0603 - val_loss: 1.1268 - val_root_mean_squared_error: 1.0593\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.1328 - root_mean_squared_error: 1.0613\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.05928\n",
      "80001/80001 [==============================] - 579s 7ms/step - loss: 1.1328 - root_mean_squared_error: 1.0613 - val_loss: 1.1393 - val_root_mean_squared_error: 1.0627\n",
      "Epoch 5/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.1305 - root_mean_squared_error: 1.0606\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.05928\n",
      "80001/80001 [==============================] - 327s 4ms/step - loss: 1.1305 - root_mean_squared_error: 1.0606 - val_loss: 1.1281 - val_root_mean_squared_error: 1.0600\n",
      "200002/200002 [==============================] - 120s 601us/step - loss: 1.1280 - root_mean_squared_error: 1.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 21:35:13,472] Trial 0 finished with value: 1.051754117012024 and parameters: {'hidden_units': 171, 'learning_rate': 0.09760134311552048, 'dropout_1': 0.33977068106260316, 'dropout_2': 0.1636598288388696}. Best is trial 0 with value: 1.051754117012024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80252\n",
      "Epoch 1/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 5.7906 - root_mean_squared_error: 1.8021\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.80238, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 308s 4ms/step - loss: 5.7906 - root_mean_squared_error: 1.8021 - val_loss: 5.2790 - val_root_mean_squared_error: 1.8024\n",
      "Epoch 2/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 5.2476 - root_mean_squared_error: 1.8021\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.80238\n",
      "80001/80001 [==============================] - 310s 4ms/step - loss: 5.2476 - root_mean_squared_error: 1.8021 - val_loss: 5.2259 - val_root_mean_squared_error: 1.8024\n",
      "Epoch 3/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 5.2476 - root_mean_squared_error: 1.8021\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.80238\n",
      "80001/80001 [==============================] - 299s 4ms/step - loss: 5.2476 - root_mean_squared_error: 1.8021 - val_loss: 5.3109 - val_root_mean_squared_error: 1.8024\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 5.2476 - root_mean_squared_error: 1.8021\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.80238\n",
      "80001/80001 [==============================] - 307s 4ms/step - loss: 5.2476 - root_mean_squared_error: 1.8021 - val_loss: 5.2703 - val_root_mean_squared_error: 1.8024\n",
      "Epoch 5/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 5.2476 - root_mean_squared_error: 1.8021\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.80238\n",
      "80001/80001 [==============================] - 300s 4ms/step - loss: 5.2476 - root_mean_squared_error: 1.8021 - val_loss: 5.3079 - val_root_mean_squared_error: 1.8024\n",
      "200002/200002 [==============================] - 119s 597us/step - loss: 5.3109 - root_mean_squared_error: 1.7919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 22:02:44,654] Trial 1 finished with value: 1.7918869256973267 and parameters: {'hidden_units': 63, 'learning_rate': 5.514154771301032, 'dropout_1': 0.10694063395501935, 'dropout_2': 0.1640389785780891}. Best is trial 0 with value: 1.051754117012024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80234\n",
      "Epoch 1/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.5241 - root_mean_squared_error: 1.1944\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.15732, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 324s 4ms/step - loss: 1.5241 - root_mean_squared_error: 1.1944 - val_loss: 1.3645 - val_root_mean_squared_error: 1.1573\n",
      "Epoch 2/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.5049 - root_mean_squared_error: 1.1907\n",
      "Epoch 2: val_root_mean_squared_error improved from 1.15732 to 1.14026, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 322s 4ms/step - loss: 1.5049 - root_mean_squared_error: 1.1907 - val_loss: 1.3153 - val_root_mean_squared_error: 1.1403\n",
      "Epoch 3/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.3407 - root_mean_squared_error: 1.1390\n",
      "Epoch 3: val_root_mean_squared_error improved from 1.14026 to 1.13099, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 321s 4ms/step - loss: 1.3406 - root_mean_squared_error: 1.1390 - val_loss: 1.2941 - val_root_mean_squared_error: 1.1310\n",
      "Epoch 4/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.3027 - root_mean_squared_error: 1.1266\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.13099\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 1.3027 - root_mean_squared_error: 1.1266 - val_loss: 1.2961 - val_root_mean_squared_error: 1.1321\n",
      "Epoch 5/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.2917 - root_mean_squared_error: 1.1218\n",
      "Epoch 5: val_root_mean_squared_error improved from 1.13099 to 1.11589, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 1.2917 - root_mean_squared_error: 1.1218 - val_loss: 1.2599 - val_root_mean_squared_error: 1.1159\n",
      "200002/200002 [==============================] - 119s 594us/step - loss: 1.2599 - root_mean_squared_error: 1.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 22:31:29,063] Trial 2 finished with value: 1.1060270071029663 and parameters: {'hidden_units': 179, 'learning_rate': 0.20942166145513416, 'dropout_1': 0.15807921511188683, 'dropout_2': 0.1870696897181974}. Best is trial 0 with value: 1.051754117012024.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80231\n",
      "Epoch 1/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.1269 - root_mean_squared_error: 0.9776\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.93299, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 309s 4ms/step - loss: 1.1269 - root_mean_squared_error: 0.9776 - val_loss: 1.0195 - val_root_mean_squared_error: 0.9330\n",
      "Epoch 2/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.1045 - root_mean_squared_error: 0.9686\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.93299\n",
      "80001/80001 [==============================] - 490s 6ms/step - loss: 1.1045 - root_mean_squared_error: 0.9686 - val_loss: 1.0691 - val_root_mean_squared_error: 0.9372\n",
      "Epoch 3/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 1.1003 - root_mean_squared_error: 0.9672\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.93299 to 0.93113, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 328s 4ms/step - loss: 1.1003 - root_mean_squared_error: 0.9672 - val_loss: 1.0487 - val_root_mean_squared_error: 0.9311\n",
      "Epoch 4/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.0972 - root_mean_squared_error: 0.9668\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.93113 to 0.92883, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 310s 4ms/step - loss: 1.0972 - root_mean_squared_error: 0.9668 - val_loss: 1.0407 - val_root_mean_squared_error: 0.9288\n",
      "Epoch 5/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.0967 - root_mean_squared_error: 0.9674\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.92883\n",
      "80001/80001 [==============================] - 302s 4ms/step - loss: 1.0967 - root_mean_squared_error: 0.9674 - val_loss: 1.0049 - val_root_mean_squared_error: 0.9307\n",
      "200002/200002 [==============================] - 122s 610us/step - loss: 1.0049 - root_mean_squared_error: 0.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 23:02:39,481] Trial 3 finished with value: 0.9213125109672546 and parameters: {'hidden_units': 40, 'learning_rate': 0.02326886436224734, 'dropout_1': 0.336563320730566, 'dropout_2': 0.23369834462444264}. Best is trial 3 with value: 0.9213125109672546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80247\n",
      "Epoch 1/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.2314 - root_mean_squared_error: 1.0021\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.96788, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 1.2314 - root_mean_squared_error: 1.0021 - val_loss: 1.1117 - val_root_mean_squared_error: 0.9679\n",
      "Epoch 2/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.2206 - root_mean_squared_error: 1.0013\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.96788\n",
      "80001/80001 [==============================] - 300s 4ms/step - loss: 1.2206 - root_mean_squared_error: 1.0013 - val_loss: 1.0663 - val_root_mean_squared_error: 0.9871\n",
      "Epoch 3/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.2157 - root_mean_squared_error: 1.0041\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.96788 to 0.96559, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 300s 4ms/step - loss: 1.2157 - root_mean_squared_error: 1.0041 - val_loss: 1.1794 - val_root_mean_squared_error: 0.9656\n",
      "Epoch 4/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.1698 - root_mean_squared_error: 1.0618\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.96559\n",
      "80001/80001 [==============================] - 305s 4ms/step - loss: 1.1698 - root_mean_squared_error: 1.0618 - val_loss: 1.1431 - val_root_mean_squared_error: 1.0504\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.1482 - root_mean_squared_error: 1.0591\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.96559\n",
      "80001/80001 [==============================] - 330s 4ms/step - loss: 1.1482 - root_mean_squared_error: 1.0591 - val_loss: 1.1309 - val_root_mean_squared_error: 1.0615\n",
      "200002/200002 [==============================] - 118s 587us/step - loss: 1.1310 - root_mean_squared_error: 1.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 23:30:34,254] Trial 4 finished with value: 1.0538694858551025 and parameters: {'hidden_units': 76, 'learning_rate': 0.0652093063307928, 'dropout_1': 0.20605335998403262, 'dropout_2': 0.21090546555443826}. Best is trial 3 with value: 0.9213125109672546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80273\n",
      "Epoch 1/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.1655 - root_mean_squared_error: 0.9755\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.93928, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 290s 4ms/step - loss: 1.1655 - root_mean_squared_error: 0.9755 - val_loss: 1.1203 - val_root_mean_squared_error: 0.9393\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.1387 - root_mean_squared_error: 0.9663\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.93928\n",
      "80001/80001 [==============================] - 290s 4ms/step - loss: 1.1387 - root_mean_squared_error: 0.9663 - val_loss: 1.1263 - val_root_mean_squared_error: 0.9487\n",
      "Epoch 3/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.1316 - root_mean_squared_error: 0.9654\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.93928\n",
      "80001/80001 [==============================] - 291s 4ms/step - loss: 1.1316 - root_mean_squared_error: 0.9654 - val_loss: 1.1168 - val_root_mean_squared_error: 0.9404\n",
      "Epoch 4/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.1292 - root_mean_squared_error: 0.9665\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.93928 to 0.93715, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 291s 4ms/step - loss: 1.1292 - root_mean_squared_error: 0.9665 - val_loss: 1.0677 - val_root_mean_squared_error: 0.9371\n",
      "Epoch 5/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 1.1223 - root_mean_squared_error: 0.9651\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.93715\n",
      "80001/80001 [==============================] - 291s 4ms/step - loss: 1.1223 - root_mean_squared_error: 0.9651 - val_loss: 1.0284 - val_root_mean_squared_error: 0.9373\n",
      "200002/200002 [==============================] - 117s 586us/step - loss: 1.0284 - root_mean_squared_error: 0.9283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 23:56:52,583] Trial 5 finished with value: 0.9283166527748108 and parameters: {'hidden_units': 26, 'learning_rate': 0.03761651941132502, 'dropout_1': 0.2663636829294608, 'dropout_2': 0.10781861521326845}. Best is trial 3 with value: 0.9213125109672546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80233\n",
      "Epoch 1/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 3.5671 - root_mean_squared_error: 1.8022\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.80212, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 293s 4ms/step - loss: 3.5671 - root_mean_squared_error: 1.8022 - val_loss: 3.4898 - val_root_mean_squared_error: 1.8021\n",
      "Epoch 2/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 3.5003 - root_mean_squared_error: 1.8022\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.80212\n",
      "80001/80001 [==============================] - 293s 4ms/step - loss: 3.5002 - root_mean_squared_error: 1.8022 - val_loss: 3.4959 - val_root_mean_squared_error: 1.8021\n",
      "Epoch 3/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 3.5002 - root_mean_squared_error: 1.8022\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.80212\n",
      "80001/80001 [==============================] - 292s 4ms/step - loss: 3.5002 - root_mean_squared_error: 1.8022 - val_loss: 3.4944 - val_root_mean_squared_error: 1.8021\n",
      "Epoch 4/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 3.5002 - root_mean_squared_error: 1.8022\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.80212\n",
      "80001/80001 [==============================] - 292s 4ms/step - loss: 3.5002 - root_mean_squared_error: 1.8022 - val_loss: 3.5015 - val_root_mean_squared_error: 1.8021\n",
      "Epoch 5/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 3.5002 - root_mean_squared_error: 1.8022\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.80212\n",
      "80001/80001 [==============================] - 293s 4ms/step - loss: 3.5002 - root_mean_squared_error: 1.8022 - val_loss: 3.4976 - val_root_mean_squared_error: 1.8021\n",
      "200002/200002 [==============================] - 118s 589us/step - loss: 3.4975 - root_mean_squared_error: 1.7916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 00:23:21,233] Trial 6 finished with value: 1.791632890701294 and parameters: {'hidden_units': 43, 'learning_rate': 1.9576898803261242, 'dropout_1': 0.13149750587585665, 'dropout_2': 0.17830798770941278}. Best is trial 3 with value: 0.9213125109672546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80260\n",
      "Epoch 1/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.2269 - root_mean_squared_error: 0.9996\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.99441, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 1.2269 - root_mean_squared_error: 0.9996 - val_loss: 1.1693 - val_root_mean_squared_error: 0.9944\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.1980 - root_mean_squared_error: 1.0039\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.99441 to 0.97406, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 310s 4ms/step - loss: 1.1980 - root_mean_squared_error: 1.0039 - val_loss: 1.1941 - val_root_mean_squared_error: 0.9741\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.1859 - root_mean_squared_error: 1.0096\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.97406 to 0.96904, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 310s 4ms/step - loss: 1.1859 - root_mean_squared_error: 1.0096 - val_loss: 1.1729 - val_root_mean_squared_error: 0.9690\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.2150 - root_mean_squared_error: 1.0142\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.96904\n",
      "80001/80001 [==============================] - 309s 4ms/step - loss: 1.2149 - root_mean_squared_error: 1.0142 - val_loss: 1.1120 - val_root_mean_squared_error: 0.9798\n",
      "Epoch 5/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.2059 - root_mean_squared_error: 1.0122\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.96904\n",
      "80001/80001 [==============================] - 308s 4ms/step - loss: 1.2059 - root_mean_squared_error: 1.0122 - val_loss: 1.1608 - val_root_mean_squared_error: 1.0046\n",
      "200002/200002 [==============================] - 118s 588us/step - loss: 1.1608 - root_mean_squared_error: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 00:51:15,122] Trial 7 finished with value: 0.9930165410041809 and parameters: {'hidden_units': 92, 'learning_rate': 0.07614453011930115, 'dropout_1': 0.10298396795437269, 'dropout_2': 0.18649188132664052}. Best is trial 3 with value: 0.9213125109672546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80253\n",
      "Epoch 1/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 8.8859 - root_mean_squared_error: 1.8022\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.80194, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 304s 4ms/step - loss: 8.8858 - root_mean_squared_error: 1.8022 - val_loss: 7.7750 - val_root_mean_squared_error: 1.8019\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 7.7340 - root_mean_squared_error: 1.8022\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.80194\n",
      "80001/80001 [==============================] - 302s 4ms/step - loss: 7.7340 - root_mean_squared_error: 1.8022 - val_loss: 7.7578 - val_root_mean_squared_error: 1.8019\n",
      "Epoch 3/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 7.7340 - root_mean_squared_error: 1.8022\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.80194\n",
      "80001/80001 [==============================] - 303s 4ms/step - loss: 7.7340 - root_mean_squared_error: 1.8022 - val_loss: 7.7266 - val_root_mean_squared_error: 1.8019\n",
      "Epoch 4/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 7.7340 - root_mean_squared_error: 1.8022\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.80194\n",
      "80001/80001 [==============================] - 304s 4ms/step - loss: 7.7340 - root_mean_squared_error: 1.8022 - val_loss: 7.6313 - val_root_mean_squared_error: 1.8019\n",
      "Epoch 5/5\n",
      "79988/80001 [============================>.] - ETA: 0s - loss: 7.7340 - root_mean_squared_error: 1.8022\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.80194\n",
      "80001/80001 [==============================] - 301s 4ms/step - loss: 7.7340 - root_mean_squared_error: 1.8022 - val_loss: 7.7508 - val_root_mean_squared_error: 1.8019\n",
      "200002/200002 [==============================] - 119s 595us/step - loss: 7.7477 - root_mean_squared_error: 1.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 01:18:35,720] Trial 8 finished with value: 1.791418433189392 and parameters: {'hidden_units': 61, 'learning_rate': 8.02631158324924, 'dropout_1': 0.17578026402440386, 'dropout_2': 0.367234722903763}. Best is trial 3 with value: 0.9213125109672546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80191\n",
      "Epoch 1/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 3.3359 - root_mean_squared_error: 1.8021\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.80248, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 297s 4ms/step - loss: 3.3359 - root_mean_squared_error: 1.8021 - val_loss: 3.3275 - val_root_mean_squared_error: 1.8025\n",
      "Epoch 2/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 3.3261 - root_mean_squared_error: 1.8021\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.80248\n",
      "80001/80001 [==============================] - 294s 4ms/step - loss: 3.3261 - root_mean_squared_error: 1.8021 - val_loss: 3.3275 - val_root_mean_squared_error: 1.8025\n",
      "Epoch 3/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 3.3261 - root_mean_squared_error: 1.8021\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.80248\n",
      "80001/80001 [==============================] - 295s 4ms/step - loss: 3.3261 - root_mean_squared_error: 1.8021 - val_loss: 3.3276 - val_root_mean_squared_error: 1.8025\n",
      "Epoch 4/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 3.3261 - root_mean_squared_error: 1.8021\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.80248\n",
      "80001/80001 [==============================] - 294s 4ms/step - loss: 3.3261 - root_mean_squared_error: 1.8021 - val_loss: 3.3275 - val_root_mean_squared_error: 1.8025\n",
      "Epoch 5/5\n",
      "79988/80001 [============================>.] - ETA: 0s - loss: 3.3261 - root_mean_squared_error: 1.8021\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.80248\n",
      "80001/80001 [==============================] - 294s 4ms/step - loss: 3.3261 - root_mean_squared_error: 1.8021 - val_loss: 3.3284 - val_root_mean_squared_error: 1.8025\n",
      "200002/200002 [==============================] - 119s 596us/step - loss: 3.3277 - root_mean_squared_error: 1.7919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 01:45:17,577] Trial 9 finished with value: 1.79192316532135 and parameters: {'hidden_units': 53, 'learning_rate': 0.7641153476739857, 'dropout_1': 0.3588458411815498, 'dropout_2': 0.16232020389637913}. Best is trial 3 with value: 0.9213125109672546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80316\n",
      "Epoch 1/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0535 - root_mean_squared_error: 0.9557\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92423, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 1.0535 - root_mean_squared_error: 0.9557 - val_loss: 0.9816 - val_root_mean_squared_error: 0.9242\n",
      "Epoch 2/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.0323 - root_mean_squared_error: 0.9469\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92423 to 0.92307, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 309s 4ms/step - loss: 1.0323 - root_mean_squared_error: 0.9469 - val_loss: 0.9774 - val_root_mean_squared_error: 0.9231\n",
      "Epoch 3/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0273 - root_mean_squared_error: 0.9455\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.92307\n",
      "80001/80001 [==============================] - 309s 4ms/step - loss: 1.0273 - root_mean_squared_error: 0.9455 - val_loss: 0.9976 - val_root_mean_squared_error: 0.9314\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.0252 - root_mean_squared_error: 0.9455\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.92307 to 0.91814, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 1.0252 - root_mean_squared_error: 0.9455 - val_loss: 0.9897 - val_root_mean_squared_error: 0.9181\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0232 - root_mean_squared_error: 0.9453\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91814\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 1.0232 - root_mean_squared_error: 0.9453 - val_loss: 0.9775 - val_root_mean_squared_error: 0.9227\n",
      "200002/200002 [==============================] - 117s 587us/step - loss: 0.9775 - root_mean_squared_error: 0.9138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 02:13:17,692] Trial 10 finished with value: 0.913781464099884 and parameters: {'hidden_units': 122, 'learning_rate': 0.015042088211059982, 'dropout_1': 0.2319893046346341, 'dropout_2': 0.3337932985234047}. Best is trial 10 with value: 0.913781464099884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80167\n",
      "Epoch 1/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.0243 - root_mean_squared_error: 0.9484\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92738, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 1.0243 - root_mean_squared_error: 0.9484 - val_loss: 0.9858 - val_root_mean_squared_error: 0.9274\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0027 - root_mean_squared_error: 0.9385\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92738 to 0.92491, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 1.0027 - root_mean_squared_error: 0.9385 - val_loss: 0.9721 - val_root_mean_squared_error: 0.9249\n",
      "Epoch 3/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9985 - root_mean_squared_error: 0.9371\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.92491 to 0.92354, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 0.9985 - root_mean_squared_error: 0.9370 - val_loss: 0.9719 - val_root_mean_squared_error: 0.9235\n",
      "Epoch 4/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 0.9960 - root_mean_squared_error: 0.9366\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.92354 to 0.91825, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 0.9960 - root_mean_squared_error: 0.9366 - val_loss: 0.9687 - val_root_mean_squared_error: 0.9183\n",
      "Epoch 5/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 0.9947 - root_mean_squared_error: 0.9366\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91825\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 0.9947 - root_mean_squared_error: 0.9366 - val_loss: 0.9781 - val_root_mean_squared_error: 0.9211\n",
      "200002/200002 [==============================] - 119s 593us/step - loss: 0.9781 - root_mean_squared_error: 0.9120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 02:41:25,066] Trial 11 finished with value: 0.9120022058486938 and parameters: {'hidden_units': 129, 'learning_rate': 0.011223730926669487, 'dropout_1': 0.23646631058605727, 'dropout_2': 0.3300819149642964}. Best is trial 11 with value: 0.9120022058486938.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80269\n",
      "Epoch 1/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0184 - root_mean_squared_error: 0.9486\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92368, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 1.0184 - root_mean_squared_error: 0.9486 - val_loss: 0.9584 - val_root_mean_squared_error: 0.9237\n",
      "Epoch 2/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 0.9970 - root_mean_squared_error: 0.9387\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92368 to 0.92314, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9970 - root_mean_squared_error: 0.9387 - val_loss: 0.9673 - val_root_mean_squared_error: 0.9231\n",
      "Epoch 3/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 0.9933 - root_mean_squared_error: 0.9373\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.92314\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9933 - root_mean_squared_error: 0.9373 - val_loss: 0.9813 - val_root_mean_squared_error: 0.9310\n",
      "Epoch 4/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9915 - root_mean_squared_error: 0.9374\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.92314\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 0.9915 - root_mean_squared_error: 0.9374 - val_loss: 0.9784 - val_root_mean_squared_error: 0.9275\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9905 - root_mean_squared_error: 0.9375\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.92314 to 0.91945, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 0.9905 - root_mean_squared_error: 0.9375 - val_loss: 0.9553 - val_root_mean_squared_error: 0.9195\n",
      "200002/200002 [==============================] - 117s 585us/step - loss: 0.9553 - root_mean_squared_error: 0.9106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 03:09:33,164] Trial 12 finished with value: 0.9106038808822632 and parameters: {'hidden_units': 134, 'learning_rate': 0.010293503565518993, 'dropout_1': 0.2382948345759743, 'dropout_2': 0.4101571376476886}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80312\n",
      "Epoch 1/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 1.0474 - root_mean_squared_error: 0.9605\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92616, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 1.0474 - root_mean_squared_error: 0.9604 - val_loss: 0.9781 - val_root_mean_squared_error: 0.9262\n",
      "Epoch 2/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0277 - root_mean_squared_error: 0.9515\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92616 to 0.91953, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 1.0277 - root_mean_squared_error: 0.9515 - val_loss: 0.9669 - val_root_mean_squared_error: 0.9195\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0247 - root_mean_squared_error: 0.9511\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.91953\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 1.0247 - root_mean_squared_error: 0.9511 - val_loss: 0.9783 - val_root_mean_squared_error: 0.9251\n",
      "Epoch 4/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.0222 - root_mean_squared_error: 0.9509\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.91953\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 1.0222 - root_mean_squared_error: 0.9509 - val_loss: 0.9632 - val_root_mean_squared_error: 0.9205\n",
      "Epoch 5/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.0210 - root_mean_squared_error: 0.9508\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91953\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 1.0210 - root_mean_squared_error: 0.9508 - val_loss: 0.9806 - val_root_mean_squared_error: 0.9274\n",
      "200002/200002 [==============================] - 119s 594us/step - loss: 0.9807 - root_mean_squared_error: 0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 03:37:39,344] Trial 13 finished with value: 0.9187701344490051 and parameters: {'hidden_units': 126, 'learning_rate': 0.011980067749167924, 'dropout_1': 0.2783369267313656, 'dropout_2': 0.4934748357757928}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80218\n",
      "Epoch 1/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.0185 - root_mean_squared_error: 0.9478\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92465, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 316s 4ms/step - loss: 1.0185 - root_mean_squared_error: 0.9478 - val_loss: 0.9833 - val_root_mean_squared_error: 0.9246\n",
      "Epoch 2/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9966 - root_mean_squared_error: 0.9373\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.92465\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 0.9966 - root_mean_squared_error: 0.9373 - val_loss: 0.9775 - val_root_mean_squared_error: 0.9263\n",
      "Epoch 3/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9920 - root_mean_squared_error: 0.9356\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.92465 to 0.91647, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 318s 4ms/step - loss: 0.9920 - root_mean_squared_error: 0.9356 - val_loss: 0.9463 - val_root_mean_squared_error: 0.9165\n",
      "Epoch 4/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 0.9900 - root_mean_squared_error: 0.9352\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.91647\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9900 - root_mean_squared_error: 0.9352 - val_loss: 0.9661 - val_root_mean_squared_error: 0.9219\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9887 - root_mean_squared_error: 0.9352\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91647\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9887 - root_mean_squared_error: 0.9352 - val_loss: 0.9607 - val_root_mean_squared_error: 0.9197\n",
      "200002/200002 [==============================] - 119s 593us/step - loss: 0.9607 - root_mean_squared_error: 0.9113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 04:06:03,836] Trial 14 finished with value: 0.9112712740898132 and parameters: {'hidden_units': 149, 'learning_rate': 0.010231870835030347, 'dropout_1': 0.2483708056027862, 'dropout_2': 0.3269067470868434}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80243\n",
      "Epoch 1/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 3.2718 - root_mean_squared_error: 1.8022\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.80193, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 3.2718 - root_mean_squared_error: 1.8022 - val_loss: 3.2695 - val_root_mean_squared_error: 1.8019\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 3.2708 - root_mean_squared_error: 1.8022\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.80193\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 3.2708 - root_mean_squared_error: 1.8022 - val_loss: 3.2702 - val_root_mean_squared_error: 1.8019\n",
      "Epoch 3/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 3.2708 - root_mean_squared_error: 1.8022\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.80193\n",
      "80001/80001 [==============================] - 317s 4ms/step - loss: 3.2708 - root_mean_squared_error: 1.8022 - val_loss: 3.2701 - val_root_mean_squared_error: 1.8019\n",
      "Epoch 4/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 3.2708 - root_mean_squared_error: 1.8022\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.80193\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 3.2708 - root_mean_squared_error: 1.8022 - val_loss: 3.2695 - val_root_mean_squared_error: 1.8019\n",
      "Epoch 5/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 3.2708 - root_mean_squared_error: 1.8022\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.80193\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 3.2708 - root_mean_squared_error: 1.8022 - val_loss: 3.2695 - val_root_mean_squared_error: 1.8019\n",
      "200002/200002 [==============================] - 118s 587us/step - loss: 3.2702 - root_mean_squared_error: 1.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 04:34:23,214] Trial 15 finished with value: 1.7913786172866821 and parameters: {'hidden_units': 157, 'learning_rate': 0.2738308220678334, 'dropout_1': 0.2801528315246426, 'dropout_2': 0.47833105879113097}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80248\n",
      "Epoch 1/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.1540 - root_mean_squared_error: 0.9785\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.94688, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 322s 4ms/step - loss: 1.1540 - root_mean_squared_error: 0.9785 - val_loss: 1.0845 - val_root_mean_squared_error: 0.9469\n",
      "Epoch 2/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 1.1250 - root_mean_squared_error: 0.9717\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.94688\n",
      "80001/80001 [==============================] - 316s 4ms/step - loss: 1.1250 - root_mean_squared_error: 0.9717 - val_loss: 1.0733 - val_root_mean_squared_error: 0.9487\n",
      "Epoch 3/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 1.1187 - root_mean_squared_error: 0.9726\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.94688 to 0.94219, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 317s 4ms/step - loss: 1.1187 - root_mean_squared_error: 0.9726 - val_loss: 1.0752 - val_root_mean_squared_error: 0.9422\n",
      "Epoch 4/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.1148 - root_mean_squared_error: 0.9733\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.94219 to 0.93789, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 1.1148 - root_mean_squared_error: 0.9733 - val_loss: 1.0461 - val_root_mean_squared_error: 0.9379\n",
      "Epoch 5/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.1156 - root_mean_squared_error: 0.9750\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.93789\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 1.1156 - root_mean_squared_error: 0.9750 - val_loss: 1.1085 - val_root_mean_squared_error: 0.9536\n",
      "200002/200002 [==============================] - 119s 597us/step - loss: 1.1085 - root_mean_squared_error: 0.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 05:02:55,138] Trial 16 finished with value: 0.9451683759689331 and parameters: {'hidden_units': 150, 'learning_rate': 0.03697494074866388, 'dropout_1': 0.1916904181178596, 'dropout_2': 0.2668145821134684}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80245\n",
      "Epoch 1/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 3.3106 - root_mean_squared_error: 1.8021\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.80218, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 325s 4ms/step - loss: 3.3106 - root_mean_squared_error: 1.8021 - val_loss: 3.3055 - val_root_mean_squared_error: 1.8022\n",
      "Epoch 2/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 3.3039 - root_mean_squared_error: 1.8021\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.80218\n",
      "80001/80001 [==============================] - 324s 4ms/step - loss: 3.3039 - root_mean_squared_error: 1.8021 - val_loss: 3.3040 - val_root_mean_squared_error: 1.8022\n",
      "Epoch 3/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 3.3040 - root_mean_squared_error: 1.8021\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.80218\n",
      "80001/80001 [==============================] - 323s 4ms/step - loss: 3.3040 - root_mean_squared_error: 1.8021 - val_loss: 3.3031 - val_root_mean_squared_error: 1.8022\n",
      "Epoch 4/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 3.3039 - root_mean_squared_error: 1.8021\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.80218\n",
      "80001/80001 [==============================] - 323s 4ms/step - loss: 3.3039 - root_mean_squared_error: 1.8021 - val_loss: 3.3055 - val_root_mean_squared_error: 1.8022\n",
      "Epoch 5/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 3.3039 - root_mean_squared_error: 1.8021\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.80218\n",
      "80001/80001 [==============================] - 323s 4ms/step - loss: 3.3039 - root_mean_squared_error: 1.8021 - val_loss: 3.3047 - val_root_mean_squared_error: 1.8022\n",
      "200002/200002 [==============================] - 120s 599us/step - loss: 3.3033 - root_mean_squared_error: 1.7916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 05:32:00,880] Trial 17 finished with value: 1.7915973663330078 and parameters: {'hidden_units': 199, 'learning_rate': 0.6369917067814438, 'dropout_1': 0.16157743016380785, 'dropout_2': 0.38876699036990237}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80242\n",
      "Epoch 1/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.1259 - root_mean_squared_error: 0.9727\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.93723, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 1.1259 - root_mean_squared_error: 0.9727 - val_loss: 1.0608 - val_root_mean_squared_error: 0.9372\n",
      "Epoch 2/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 1.1001 - root_mean_squared_error: 0.9653\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.93723\n",
      "80001/80001 [==============================] - 308s 4ms/step - loss: 1.1001 - root_mean_squared_error: 0.9653 - val_loss: 1.0479 - val_root_mean_squared_error: 0.9415\n",
      "Epoch 3/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.0945 - root_mean_squared_error: 0.9649\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.93723 to 0.93431, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 308s 4ms/step - loss: 1.0945 - root_mean_squared_error: 0.9649 - val_loss: 1.0524 - val_root_mean_squared_error: 0.9343\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.0899 - root_mean_squared_error: 0.9648\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.93431 to 0.93401, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 309s 4ms/step - loss: 1.0899 - root_mean_squared_error: 0.9648 - val_loss: 1.0511 - val_root_mean_squared_error: 0.9340\n",
      "Epoch 5/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0885 - root_mean_squared_error: 0.9656\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.93401 to 0.93301, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 309s 4ms/step - loss: 1.0885 - root_mean_squared_error: 0.9656 - val_loss: 1.0370 - val_root_mean_squared_error: 0.9330\n",
      "200002/200002 [==============================] - 119s 596us/step - loss: 1.0370 - root_mean_squared_error: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 05:59:54,135] Trial 18 finished with value: 0.9232550859451294 and parameters: {'hidden_units': 106, 'learning_rate': 0.028825835207484878, 'dropout_1': 0.22421446977819665, 'dropout_2': 0.28232005988043407}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80230\n",
      "Epoch 1/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.2778 - root_mean_squared_error: 1.1124\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.10566, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 1.2778 - root_mean_squared_error: 1.1124 - val_loss: 1.2369 - val_root_mean_squared_error: 1.1057\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.2270 - root_mean_squared_error: 1.0954\n",
      "Epoch 2: val_root_mean_squared_error improved from 1.10566 to 1.09000, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 1.2270 - root_mean_squared_error: 1.0954 - val_loss: 1.1972 - val_root_mean_squared_error: 1.0900\n",
      "Epoch 3/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.1905 - root_mean_squared_error: 1.0820\n",
      "Epoch 3: val_root_mean_squared_error improved from 1.09000 to 1.07800, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 1.1905 - root_mean_squared_error: 1.0820 - val_loss: 1.1796 - val_root_mean_squared_error: 1.0780\n",
      "Epoch 4/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.1756 - root_mean_squared_error: 1.0775\n",
      "Epoch 4: val_root_mean_squared_error improved from 1.07800 to 1.07670, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 1.1756 - root_mean_squared_error: 1.0775 - val_loss: 1.1680 - val_root_mean_squared_error: 1.0767\n",
      "Epoch 5/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.1687 - root_mean_squared_error: 1.0749\n",
      "Epoch 5: val_root_mean_squared_error improved from 1.07670 to 1.07312, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 1.1687 - root_mean_squared_error: 1.0749 - val_loss: 1.1611 - val_root_mean_squared_error: 1.0731\n",
      "200002/200002 [==============================] - 118s 588us/step - loss: 1.1611 - root_mean_squared_error: 1.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 06:28:00,728] Trial 19 finished with value: 1.0641483068466187 and parameters: {'hidden_units': 141, 'learning_rate': 0.14624943616205444, 'dropout_1': 0.2917147455311421, 'dropout_2': 0.41519252895125436}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80197\n",
      "Epoch 1/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0529 - root_mean_squared_error: 0.9655\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.93726, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 1.0529 - root_mean_squared_error: 0.9655 - val_loss: 0.9952 - val_root_mean_squared_error: 0.9373\n",
      "Epoch 2/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0297 - root_mean_squared_error: 0.9550\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.93726 to 0.93102, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 308s 4ms/step - loss: 1.0297 - root_mean_squared_error: 0.9550 - val_loss: 0.9803 - val_root_mean_squared_error: 0.9310\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0255 - root_mean_squared_error: 0.9530\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.93102 to 0.92032, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 309s 4ms/step - loss: 1.0255 - root_mean_squared_error: 0.9530 - val_loss: 0.9643 - val_root_mean_squared_error: 0.9203\n",
      "Epoch 4/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0237 - root_mean_squared_error: 0.9523\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.92032\n",
      "80001/80001 [==============================] - 2791s 35ms/step - loss: 1.0237 - root_mean_squared_error: 0.9523 - val_loss: 0.9766 - val_root_mean_squared_error: 0.9290\n",
      "Epoch 5/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0225 - root_mean_squared_error: 0.9519\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.92032\n",
      "80001/80001 [==============================] - 1831s 23ms/step - loss: 1.0225 - root_mean_squared_error: 0.9519 - val_loss: 0.9938 - val_root_mean_squared_error: 0.9332\n",
      "200002/200002 [==============================] - 126s 630us/step - loss: 0.9938 - root_mean_squared_error: 0.9239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 08:02:44,746] Trial 20 finished with value: 0.9239332675933838 and parameters: {'hidden_units': 100, 'learning_rate': 0.010189790514512726, 'dropout_1': 0.3801629991854579, 'dropout_2': 0.2934647378568958}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80305\n",
      "Epoch 1/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.0808 - root_mean_squared_error: 0.9633\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92666, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 332s 4ms/step - loss: 1.0808 - root_mean_squared_error: 0.9632 - val_loss: 1.0077 - val_root_mean_squared_error: 0.9267\n",
      "Epoch 2/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 1.0586 - root_mean_squared_error: 0.9548\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.92666\n",
      "80001/80001 [==============================] - 335s 4ms/step - loss: 1.0586 - root_mean_squared_error: 0.9548 - val_loss: 1.0288 - val_root_mean_squared_error: 0.9392\n",
      "Epoch 3/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0542 - root_mean_squared_error: 0.9539\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.92666\n",
      "80001/80001 [==============================] - 324s 4ms/step - loss: 1.0542 - root_mean_squared_error: 0.9539 - val_loss: 1.0052 - val_root_mean_squared_error: 0.9323\n",
      "Epoch 4/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0506 - root_mean_squared_error: 0.9536\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.92666 to 0.92264, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 1.0506 - root_mean_squared_error: 0.9536 - val_loss: 0.9911 - val_root_mean_squared_error: 0.9226\n",
      "Epoch 5/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 1.0497 - root_mean_squared_error: 0.9543\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.92264 to 0.92209, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 324s 4ms/step - loss: 1.0497 - root_mean_squared_error: 0.9543 - val_loss: 0.9958 - val_root_mean_squared_error: 0.9221\n",
      "200002/200002 [==============================] - 140s 698us/step - loss: 0.9958 - root_mean_squared_error: 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 08:32:22,344] Trial 21 finished with value: 0.9126924872398376 and parameters: {'hidden_units': 134, 'learning_rate': 0.018762419797413974, 'dropout_1': 0.24123530465909734, 'dropout_2': 0.32704692330046675}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80256\n",
      "Epoch 1/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0077 - root_mean_squared_error: 0.9443\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92014, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 487s 6ms/step - loss: 1.0077 - root_mean_squared_error: 0.9443 - val_loss: 0.9634 - val_root_mean_squared_error: 0.9201\n",
      "Epoch 2/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 0.9879 - root_mean_squared_error: 0.9349\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92014 to 0.91330, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 331s 4ms/step - loss: 0.9879 - root_mean_squared_error: 0.9349 - val_loss: 0.9542 - val_root_mean_squared_error: 0.9133\n",
      "Epoch 3/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 0.9839 - root_mean_squared_error: 0.9337\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.91330\n",
      "80001/80001 [==============================] - 350s 4ms/step - loss: 0.9839 - root_mean_squared_error: 0.9337 - val_loss: 0.9443 - val_root_mean_squared_error: 0.9145\n",
      "Epoch 4/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 0.9823 - root_mean_squared_error: 0.9336\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.91330\n",
      "80001/80001 [==============================] - 338s 4ms/step - loss: 0.9823 - root_mean_squared_error: 0.9336 - val_loss: 0.9591 - val_root_mean_squared_error: 0.9196\n",
      "Epoch 5/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 0.9816 - root_mean_squared_error: 0.9336\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91330\n",
      "80001/80001 [==============================] - 384s 5ms/step - loss: 0.9816 - root_mean_squared_error: 0.9336 - val_loss: 0.9667 - val_root_mean_squared_error: 0.9265\n",
      "200002/200002 [==============================] - 142s 708us/step - loss: 0.9667 - root_mean_squared_error: 0.9185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 09:06:26,012] Trial 22 finished with value: 0.9185031056404114 and parameters: {'hidden_units': 116, 'learning_rate': 0.010194275078999091, 'dropout_1': 0.20388618995638916, 'dropout_2': 0.413381481580795}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80250\n",
      "Epoch 1/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.2109 - root_mean_squared_error: 1.0045\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.96275, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 457s 6ms/step - loss: 1.2109 - root_mean_squared_error: 1.0045 - val_loss: 1.1915 - val_root_mean_squared_error: 0.9628\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.1864 - root_mean_squared_error: 0.9978\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.96275\n",
      "80001/80001 [==============================] - 402s 5ms/step - loss: 1.1864 - root_mean_squared_error: 0.9978 - val_loss: 1.2168 - val_root_mean_squared_error: 0.9998\n",
      "Epoch 3/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.1768 - root_mean_squared_error: 0.9996\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.96275\n",
      "80001/80001 [==============================] - 433s 5ms/step - loss: 1.1768 - root_mean_squared_error: 0.9996 - val_loss: 1.0477 - val_root_mean_squared_error: 0.9666\n",
      "Epoch 4/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 1.1700 - root_mean_squared_error: 1.0007\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.96275 to 0.95598, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 427s 5ms/step - loss: 1.1700 - root_mean_squared_error: 1.0007 - val_loss: 1.1039 - val_root_mean_squared_error: 0.9560\n",
      "Epoch 5/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.1805 - root_mean_squared_error: 1.0068\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.95598\n",
      "80001/80001 [==============================] - 411s 5ms/step - loss: 1.1805 - root_mean_squared_error: 1.0068 - val_loss: 1.1308 - val_root_mean_squared_error: 0.9865\n",
      "200002/200002 [==============================] - 185s 925us/step - loss: 1.1308 - root_mean_squared_error: 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 09:45:13,346] Trial 23 finished with value: 0.9764620065689087 and parameters: {'hidden_units': 161, 'learning_rate': 0.046925896143486086, 'dropout_1': 0.24601234804045613, 'dropout_2': 0.3332594350307141}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80147\n",
      "Epoch 1/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0993 - root_mean_squared_error: 0.9687\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.93275, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 382s 5ms/step - loss: 1.0993 - root_mean_squared_error: 0.9687 - val_loss: 1.0336 - val_root_mean_squared_error: 0.9328\n",
      "Epoch 2/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0765 - root_mean_squared_error: 0.9591\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.93275\n",
      "80001/80001 [==============================] - 368s 5ms/step - loss: 1.0765 - root_mean_squared_error: 0.9591 - val_loss: 1.0220 - val_root_mean_squared_error: 0.9352\n",
      "Epoch 3/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0712 - root_mean_squared_error: 0.9578\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.93275\n",
      "80001/80001 [==============================] - 377s 5ms/step - loss: 1.0712 - root_mean_squared_error: 0.9578 - val_loss: 1.0336 - val_root_mean_squared_error: 0.9375\n",
      "Epoch 4/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 1.0682 - root_mean_squared_error: 0.9575\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.93275 to 0.93261, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 375s 5ms/step - loss: 1.0682 - root_mean_squared_error: 0.9575 - val_loss: 1.0212 - val_root_mean_squared_error: 0.9326\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0656 - root_mean_squared_error: 0.9574\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.93261 to 0.92729, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 396s 5ms/step - loss: 1.0656 - root_mean_squared_error: 0.9574 - val_loss: 1.0098 - val_root_mean_squared_error: 0.9273\n",
      "200002/200002 [==============================] - 138s 691us/step - loss: 1.0098 - root_mean_squared_error: 0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 10:19:21,508] Trial 24 finished with value: 0.9174851179122925 and parameters: {'hidden_units': 188, 'learning_rate': 0.019474441450211207, 'dropout_1': 0.29929155517952877, 'dropout_2': 0.23502882499118355}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80160\n",
      "Epoch 1/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.1038 - root_mean_squared_error: 0.9731\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.94187, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 384s 5ms/step - loss: 1.1038 - root_mean_squared_error: 0.9731 - val_loss: 1.0581 - val_root_mean_squared_error: 0.9419\n",
      "Epoch 2/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0821 - root_mean_squared_error: 0.9664\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.94187 to 0.93924, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 488s 6ms/step - loss: 1.0821 - root_mean_squared_error: 0.9664 - val_loss: 1.0362 - val_root_mean_squared_error: 0.9392\n",
      "Epoch 3/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0774 - root_mean_squared_error: 0.9668\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.93924 to 0.93327, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 365s 5ms/step - loss: 1.0774 - root_mean_squared_error: 0.9668 - val_loss: 1.0194 - val_root_mean_squared_error: 0.9333\n",
      "Epoch 4/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0728 - root_mean_squared_error: 0.9666\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.93327\n",
      "80001/80001 [==============================] - 390s 5ms/step - loss: 1.0728 - root_mean_squared_error: 0.9666 - val_loss: 1.0000 - val_root_mean_squared_error: 0.9368\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0727 - root_mean_squared_error: 0.9675\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.93327 to 0.92874, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 408s 5ms/step - loss: 1.0727 - root_mean_squared_error: 0.9675 - val_loss: 0.9872 - val_root_mean_squared_error: 0.9287\n",
      "200002/200002 [==============================] - 148s 741us/step - loss: 0.9872 - root_mean_squared_error: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 10:56:12,162] Trial 25 finished with value: 0.9196734428405762 and parameters: {'hidden_units': 143, 'learning_rate': 0.02317223192274659, 'dropout_1': 0.2174679709588774, 'dropout_2': 0.43323630009239916}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80221\n",
      "Epoch 1/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 3.3060 - root_mean_squared_error: 1.8021\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.80246, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 476s 6ms/step - loss: 3.3060 - root_mean_squared_error: 1.8021 - val_loss: 3.3034 - val_root_mean_squared_error: 1.8025\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 3.3017 - root_mean_squared_error: 1.8021\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.80246\n",
      "80001/80001 [==============================] - 638s 8ms/step - loss: 3.3017 - root_mean_squared_error: 1.8021 - val_loss: 3.3027 - val_root_mean_squared_error: 1.8025\n",
      "Epoch 3/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 3.3017 - root_mean_squared_error: 1.8021\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.80246\n",
      "80001/80001 [==============================] - 407s 5ms/step - loss: 3.3017 - root_mean_squared_error: 1.8021 - val_loss: 3.3035 - val_root_mean_squared_error: 1.8025\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 3.3018 - root_mean_squared_error: 1.8021\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.80246\n",
      "80001/80001 [==============================] - 382s 5ms/step - loss: 3.3018 - root_mean_squared_error: 1.8021 - val_loss: 3.3026 - val_root_mean_squared_error: 1.8025\n",
      "Epoch 5/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 3.3018 - root_mean_squared_error: 1.8021\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.80246\n",
      "80001/80001 [==============================] - 375s 5ms/step - loss: 3.3018 - root_mean_squared_error: 1.8021 - val_loss: 3.3020 - val_root_mean_squared_error: 1.8025\n",
      "200002/200002 [==============================] - 141s 706us/step - loss: 3.3034 - root_mean_squared_error: 1.7919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 11:36:44,609] Trial 26 finished with value: 1.7919361591339111 and parameters: {'hidden_units': 85, 'learning_rate': 0.5330968204789419, 'dropout_1': 0.24768428720603783, 'dropout_2': 0.36117648389515983}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80243\n",
      "Epoch 1/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.1658 - root_mean_squared_error: 1.0694\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.06312, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 433s 5ms/step - loss: 1.1658 - root_mean_squared_error: 1.0694 - val_loss: 1.1432 - val_root_mean_squared_error: 1.0631\n",
      "Epoch 2/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.1407 - root_mean_squared_error: 1.0636\n",
      "Epoch 2: val_root_mean_squared_error improved from 1.06312 to 1.06189, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 377s 5ms/step - loss: 1.1407 - root_mean_squared_error: 1.0636 - val_loss: 1.1337 - val_root_mean_squared_error: 1.0619\n",
      "Epoch 3/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.1387 - root_mean_squared_error: 1.0629\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.06189\n",
      "80001/80001 [==============================] - 434s 5ms/step - loss: 1.1387 - root_mean_squared_error: 1.0629 - val_loss: 1.1351 - val_root_mean_squared_error: 1.0625\n",
      "Epoch 4/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.1352 - root_mean_squared_error: 1.0620\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.06189\n",
      "80001/80001 [==============================] - 342s 4ms/step - loss: 1.1352 - root_mean_squared_error: 1.0620 - val_loss: 1.1381 - val_root_mean_squared_error: 1.0640\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.1348 - root_mean_squared_error: 1.0618\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.06189\n",
      "80001/80001 [==============================] - 346s 4ms/step - loss: 1.1348 - root_mean_squared_error: 1.0618 - val_loss: 1.1409 - val_root_mean_squared_error: 1.0651\n",
      "200002/200002 [==============================] - 131s 655us/step - loss: 1.1410 - root_mean_squared_error: 1.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 12:11:26,136] Trial 27 finished with value: 1.0556641817092896 and parameters: {'hidden_units': 112, 'learning_rate': 0.1212418042920251, 'dropout_1': 0.3138456612676207, 'dropout_2': 0.3035754863465903}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80120\n",
      "Epoch 1/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.1816 - root_mean_squared_error: 0.9863\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.95557, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 325s 4ms/step - loss: 1.1816 - root_mean_squared_error: 0.9863 - val_loss: 1.0991 - val_root_mean_squared_error: 0.9556\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.1524 - root_mean_squared_error: 0.9800\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.95557 to 0.95349, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 324s 4ms/step - loss: 1.1524 - root_mean_squared_error: 0.9800 - val_loss: 1.1143 - val_root_mean_squared_error: 0.9535\n",
      "Epoch 3/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.1437 - root_mean_squared_error: 0.9806\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.95349 to 0.94155, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 343s 4ms/step - loss: 1.1437 - root_mean_squared_error: 0.9806 - val_loss: 1.0839 - val_root_mean_squared_error: 0.9415\n",
      "Epoch 4/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 1.1409 - root_mean_squared_error: 0.9838\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.94155\n",
      "80001/80001 [==============================] - 347s 4ms/step - loss: 1.1409 - root_mean_squared_error: 0.9838 - val_loss: 1.1601 - val_root_mean_squared_error: 0.9618\n",
      "Epoch 5/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.1394 - root_mean_squared_error: 0.9846\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.94155\n",
      "80001/80001 [==============================] - 334s 4ms/step - loss: 1.1394 - root_mean_squared_error: 0.9846 - val_loss: 1.0838 - val_root_mean_squared_error: 0.9774\n",
      "200002/200002 [==============================] - 129s 646us/step - loss: 1.0838 - root_mean_squared_error: 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 12:41:45,743] Trial 28 finished with value: 0.9696416854858398 and parameters: {'hidden_units': 9, 'learning_rate': 0.04892858531172024, 'dropout_1': 0.1888531966115934, 'dropout_2': 0.27003502193059525}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80240\n",
      "Epoch 1/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 3.5134 - root_mean_squared_error: 1.8022\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.80211, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 419s 5ms/step - loss: 3.5134 - root_mean_squared_error: 1.8022 - val_loss: 3.4522 - val_root_mean_squared_error: 1.8021\n",
      "Epoch 2/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 3.4567 - root_mean_squared_error: 1.8022\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.80211\n",
      "80001/80001 [==============================] - 408s 5ms/step - loss: 3.4567 - root_mean_squared_error: 1.8022 - val_loss: 3.4702 - val_root_mean_squared_error: 1.8021\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 3.4567 - root_mean_squared_error: 1.8022\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 1.80211\n",
      "80001/80001 [==============================] - 429s 5ms/step - loss: 3.4567 - root_mean_squared_error: 1.8022 - val_loss: 3.4569 - val_root_mean_squared_error: 1.8021\n",
      "Epoch 4/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 3.4567 - root_mean_squared_error: 1.8022\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.80211\n",
      "80001/80001 [==============================] - 461s 6ms/step - loss: 3.4567 - root_mean_squared_error: 1.8022 - val_loss: 3.4632 - val_root_mean_squared_error: 1.8021\n",
      "Epoch 5/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 3.4567 - root_mean_squared_error: 1.8022\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.80211\n",
      "80001/80001 [==============================] - 353s 4ms/step - loss: 3.4567 - root_mean_squared_error: 1.8022 - val_loss: 3.4616 - val_root_mean_squared_error: 1.8021\n",
      "200002/200002 [==============================] - 190s 950us/step - loss: 3.4595 - root_mean_squared_error: 1.7916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 13:19:40,330] Trial 29 finished with value: 1.7915847301483154 and parameters: {'hidden_units': 169, 'learning_rate': 1.803520868156523, 'dropout_1': 0.261509461680196, 'dropout_2': 0.4498908489923979}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80332\n",
      "Epoch 1/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0786 - root_mean_squared_error: 0.9625\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.94068, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 414s 5ms/step - loss: 1.0786 - root_mean_squared_error: 0.9625 - val_loss: 1.0305 - val_root_mean_squared_error: 0.9407\n",
      "Epoch 2/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.0528 - root_mean_squared_error: 0.9518\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.94068 to 0.92135, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 408s 5ms/step - loss: 1.0528 - root_mean_squared_error: 0.9518 - val_loss: 1.0106 - val_root_mean_squared_error: 0.9214\n",
      "Epoch 3/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.0491 - root_mean_squared_error: 0.9503\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.92135\n",
      "80001/80001 [==============================] - 375s 5ms/step - loss: 1.0491 - root_mean_squared_error: 0.9502 - val_loss: 1.0093 - val_root_mean_squared_error: 0.9223\n",
      "Epoch 4/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0473 - root_mean_squared_error: 0.9497\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.92135\n",
      "80001/80001 [==============================] - 377s 5ms/step - loss: 1.0473 - root_mean_squared_error: 0.9497 - val_loss: 1.0815 - val_root_mean_squared_error: 0.9661\n",
      "Epoch 5/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0447 - root_mean_squared_error: 0.9487\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.92135 to 0.92091, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 389s 5ms/step - loss: 1.0447 - root_mean_squared_error: 0.9487 - val_loss: 0.9857 - val_root_mean_squared_error: 0.9209\n",
      "200002/200002 [==============================] - 135s 672us/step - loss: 0.9856 - root_mean_squared_error: 0.9114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 13:54:59,529] Trial 30 finished with value: 0.911369264125824 and parameters: {'hidden_units': 128, 'learning_rate': 0.015879704996950923, 'dropout_1': 0.31898428009170104, 'dropout_2': 0.12954052734813745}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80250\n",
      "Epoch 1/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0823 - root_mean_squared_error: 0.9642\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.93734, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 336s 4ms/step - loss: 1.0823 - root_mean_squared_error: 0.9642 - val_loss: 1.0310 - val_root_mean_squared_error: 0.9373\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.0556 - root_mean_squared_error: 0.9533\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.93734 to 0.93081, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 359s 4ms/step - loss: 1.0556 - root_mean_squared_error: 0.9533 - val_loss: 0.9959 - val_root_mean_squared_error: 0.9308\n",
      "Epoch 3/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.0521 - root_mean_squared_error: 0.9515\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.93081 to 0.92821, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 490s 6ms/step - loss: 1.0521 - root_mean_squared_error: 0.9515 - val_loss: 1.0138 - val_root_mean_squared_error: 0.9282\n",
      "Epoch 4/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.0500 - root_mean_squared_error: 0.9510\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.92821\n",
      "80001/80001 [==============================] - 442s 6ms/step - loss: 1.0500 - root_mean_squared_error: 0.9510 - val_loss: 1.0138 - val_root_mean_squared_error: 0.9318\n",
      "Epoch 5/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0486 - root_mean_squared_error: 0.9504\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.92821 to 0.92411, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 409s 5ms/step - loss: 1.0486 - root_mean_squared_error: 0.9504 - val_loss: 1.0021 - val_root_mean_squared_error: 0.9241\n",
      "200002/200002 [==============================] - 142s 711us/step - loss: 1.0020 - root_mean_squared_error: 0.9151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 14:31:38,222] Trial 31 finished with value: 0.91511470079422 and parameters: {'hidden_units': 129, 'learning_rate': 0.01591685740405841, 'dropout_1': 0.33269817777027927, 'dropout_2': 0.11596521155062675}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80233\n",
      "Epoch 1/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0556 - root_mean_squared_error: 0.9651\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92099, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 441s 5ms/step - loss: 1.0556 - root_mean_squared_error: 0.9651 - val_loss: 0.9652 - val_root_mean_squared_error: 0.9210\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0297 - root_mean_squared_error: 0.9534\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.92099\n",
      "80001/80001 [==============================] - 399s 5ms/step - loss: 1.0297 - root_mean_squared_error: 0.9534 - val_loss: 1.0046 - val_root_mean_squared_error: 0.9443\n",
      "Epoch 3/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0236 - root_mean_squared_error: 0.9509\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.92099\n",
      "80001/80001 [==============================] - 522s 7ms/step - loss: 1.0236 - root_mean_squared_error: 0.9509 - val_loss: 0.9943 - val_root_mean_squared_error: 0.9337\n",
      "Epoch 4/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0217 - root_mean_squared_error: 0.9500\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.92099\n",
      "80001/80001 [==============================] - 397s 5ms/step - loss: 1.0217 - root_mean_squared_error: 0.9500 - val_loss: 1.0088 - val_root_mean_squared_error: 0.9408\n",
      "Epoch 5/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0206 - root_mean_squared_error: 0.9493\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.92099\n",
      "80001/80001 [==============================] - 515s 6ms/step - loss: 1.0206 - root_mean_squared_error: 0.9493 - val_loss: 0.9863 - val_root_mean_squared_error: 0.9328\n",
      "200002/200002 [==============================] - 125s 626us/step - loss: 0.9863 - root_mean_squared_error: 0.9243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 15:11:55,084] Trial 32 finished with value: 0.9242674708366394 and parameters: {'hidden_units': 149, 'learning_rate': 0.01022688600753404, 'dropout_1': 0.38885104696745, 'dropout_2': 0.14474973794334992}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80245\n",
      "Epoch 1/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.1528 - root_mean_squared_error: 0.9835\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.93717, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 426s 5ms/step - loss: 1.1528 - root_mean_squared_error: 0.9835 - val_loss: 1.0703 - val_root_mean_squared_error: 0.9372\n",
      "Epoch 2/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.1280 - root_mean_squared_error: 0.9747\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.93717 to 0.93596, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 421s 5ms/step - loss: 1.1280 - root_mean_squared_error: 0.9747 - val_loss: 1.0933 - val_root_mean_squared_error: 0.9360\n",
      "Epoch 3/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.1229 - root_mean_squared_error: 0.9749\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.93596 to 0.93178, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 521s 7ms/step - loss: 1.1229 - root_mean_squared_error: 0.9749 - val_loss: 1.0851 - val_root_mean_squared_error: 0.9318\n",
      "Epoch 4/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.1173 - root_mean_squared_error: 0.9744\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.93178\n",
      "80001/80001 [==============================] - 408s 5ms/step - loss: 1.1173 - root_mean_squared_error: 0.9744 - val_loss: 1.0299 - val_root_mean_squared_error: 0.9345\n",
      "Epoch 5/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.1146 - root_mean_squared_error: 0.9746\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.93178 to 0.93168, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 522s 7ms/step - loss: 1.1146 - root_mean_squared_error: 0.9746 - val_loss: 1.0422 - val_root_mean_squared_error: 0.9317\n",
      "200002/200002 [==============================] - 175s 873us/step - loss: 1.0422 - root_mean_squared_error: 0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 15:53:32,263] Trial 33 finished with value: 0.9221453070640564 and parameters: {'hidden_units': 170, 'learning_rate': 0.02936082882554648, 'dropout_1': 0.3127656852863926, 'dropout_2': 0.2572161607282522}. Best is trial 12 with value: 0.9106038808822632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80259\n",
      "Epoch 1/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0234 - root_mean_squared_error: 0.9430\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92485, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 430s 5ms/step - loss: 1.0234 - root_mean_squared_error: 0.9430 - val_loss: 0.9816 - val_root_mean_squared_error: 0.9248\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0003 - root_mean_squared_error: 0.9327\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92485 to 0.91749, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 402s 5ms/step - loss: 1.0003 - root_mean_squared_error: 0.9327 - val_loss: 0.9815 - val_root_mean_squared_error: 0.9175\n",
      "Epoch 3/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9963 - root_mean_squared_error: 0.9311\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.91749\n",
      "80001/80001 [==============================] - 395s 5ms/step - loss: 0.9963 - root_mean_squared_error: 0.9311 - val_loss: 0.9761 - val_root_mean_squared_error: 0.9178\n",
      "Epoch 4/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 0.9954 - root_mean_squared_error: 0.9303\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.91749\n",
      "80001/80001 [==============================] - 399s 5ms/step - loss: 0.9954 - root_mean_squared_error: 0.9303 - val_loss: 0.9841 - val_root_mean_squared_error: 0.9248\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9939 - root_mean_squared_error: 0.9300\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.91749 to 0.91225, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 426s 5ms/step - loss: 0.9939 - root_mean_squared_error: 0.9300 - val_loss: 0.9627 - val_root_mean_squared_error: 0.9122\n",
      "200002/200002 [==============================] - 146s 730us/step - loss: 0.9627 - root_mean_squared_error: 0.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 16:30:38,026] Trial 34 finished with value: 0.9028832316398621 and parameters: {'hidden_units': 138, 'learning_rate': 0.015051483037093803, 'dropout_1': 0.1392873357515348, 'dropout_2': 0.20602571171917644}. Best is trial 34 with value: 0.9028832316398621.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80111\n",
      "Epoch 1/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.2209 - root_mean_squared_error: 0.9929\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.96298, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 439s 5ms/step - loss: 1.2209 - root_mean_squared_error: 0.9929 - val_loss: 1.1101 - val_root_mean_squared_error: 0.9630\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.1861 - root_mean_squared_error: 0.9876\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.96298 to 0.95364, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 573s 7ms/step - loss: 1.1861 - root_mean_squared_error: 0.9876 - val_loss: 1.1933 - val_root_mean_squared_error: 0.9536\n",
      "Epoch 3/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.1818 - root_mean_squared_error: 0.9888\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.95364\n",
      "80001/80001 [==============================] - 501s 6ms/step - loss: 1.1819 - root_mean_squared_error: 0.9888 - val_loss: 1.0820 - val_root_mean_squared_error: 0.9630\n",
      "Epoch 4/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.1774 - root_mean_squared_error: 1.0003\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.95364\n",
      "80001/80001 [==============================] - 532s 7ms/step - loss: 1.1774 - root_mean_squared_error: 1.0003 - val_loss: 1.1264 - val_root_mean_squared_error: 0.9786\n",
      "Epoch 5/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.1700 - root_mean_squared_error: 1.0235\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.95364\n",
      "80001/80001 [==============================] - 559s 7ms/step - loss: 1.1700 - root_mean_squared_error: 1.0235 - val_loss: 1.1352 - val_root_mean_squared_error: 1.0586\n",
      "200002/200002 [==============================] - 184s 915us/step - loss: 1.1352 - root_mean_squared_error: 1.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 17:17:31,099] Trial 35 finished with value: 1.050502896308899 and parameters: {'hidden_units': 157, 'learning_rate': 0.06689850448720275, 'dropout_1': 0.12808079300911188, 'dropout_2': 0.13778498133622483}. Best is trial 34 with value: 0.9028832316398621.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80171\n",
      "Epoch 1/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0317 - root_mean_squared_error: 0.9447\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92643, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 546s 7ms/step - loss: 1.0317 - root_mean_squared_error: 0.9447 - val_loss: 1.0039 - val_root_mean_squared_error: 0.9264\n",
      "Epoch 2/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.0082 - root_mean_squared_error: 0.9343\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92643 to 0.91408, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 392s 5ms/step - loss: 1.0082 - root_mean_squared_error: 0.9343 - val_loss: 0.9615 - val_root_mean_squared_error: 0.9141\n",
      "Epoch 3/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.0038 - root_mean_squared_error: 0.9326\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.91408\n",
      "80001/80001 [==============================] - 513s 6ms/step - loss: 1.0038 - root_mean_squared_error: 0.9326 - val_loss: 0.9683 - val_root_mean_squared_error: 0.9148\n",
      "Epoch 4/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0007 - root_mean_squared_error: 0.9322\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.91408 to 0.91365, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 578s 7ms/step - loss: 1.0007 - root_mean_squared_error: 0.9322 - val_loss: 0.9581 - val_root_mean_squared_error: 0.9136\n",
      "Epoch 5/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9990 - root_mean_squared_error: 0.9326\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91365\n",
      "80001/80001 [==============================] - 531s 7ms/step - loss: 0.9990 - root_mean_squared_error: 0.9326 - val_loss: 0.9613 - val_root_mean_squared_error: 0.9145\n",
      "200002/200002 [==============================] - 175s 875us/step - loss: 0.9614 - root_mean_squared_error: 0.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 18:03:34,634] Trial 36 finished with value: 0.9052572250366211 and parameters: {'hidden_units': 139, 'learning_rate': 0.01664496679677549, 'dropout_1': 0.13723925063689446, 'dropout_2': 0.2104391719255713}. Best is trial 34 with value: 0.9028832316398621.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80244\n",
      "Epoch 1/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0891 - root_mean_squared_error: 0.9574\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92883, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 378s 5ms/step - loss: 1.0891 - root_mean_squared_error: 0.9574 - val_loss: 1.0458 - val_root_mean_squared_error: 0.9288\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.0630 - root_mean_squared_error: 0.9482\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.92883\n",
      "80001/80001 [==============================] - 362s 5ms/step - loss: 1.0630 - root_mean_squared_error: 0.9482 - val_loss: 1.0383 - val_root_mean_squared_error: 0.9313\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0557 - root_mean_squared_error: 0.9475\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.92883 to 0.92256, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 343s 4ms/step - loss: 1.0557 - root_mean_squared_error: 0.9475 - val_loss: 0.9829 - val_root_mean_squared_error: 0.9226\n",
      "Epoch 4/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.0436 - root_mean_squared_error: 0.9474\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.92256\n",
      "80001/80001 [==============================] - 336s 4ms/step - loss: 1.0436 - root_mean_squared_error: 0.9474 - val_loss: 1.0011 - val_root_mean_squared_error: 0.9335\n",
      "Epoch 5/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.0433 - root_mean_squared_error: 0.9488\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.92256\n",
      "80001/80001 [==============================] - 336s 4ms/step - loss: 1.0433 - root_mean_squared_error: 0.9488 - val_loss: 0.9935 - val_root_mean_squared_error: 0.9238\n",
      "200002/200002 [==============================] - 125s 626us/step - loss: 0.9935 - root_mean_squared_error: 0.9148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 18:35:14,915] Trial 37 finished with value: 0.9147647023200989 and parameters: {'hidden_units': 180, 'learning_rate': 0.026457318621607637, 'dropout_1': 0.12987489651621525, 'dropout_2': 0.20556538730737825}. Best is trial 34 with value: 0.9028832316398621.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80275\n",
      "Epoch 1/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.1621 - root_mean_squared_error: 0.9750\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.95052, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 336s 4ms/step - loss: 1.1621 - root_mean_squared_error: 0.9750 - val_loss: 1.0701 - val_root_mean_squared_error: 0.9505\n",
      "Epoch 2/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.1285 - root_mean_squared_error: 0.9676\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.95052 to 0.93628, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 327s 4ms/step - loss: 1.1285 - root_mean_squared_error: 0.9676 - val_loss: 1.0604 - val_root_mean_squared_error: 0.9363\n",
      "Epoch 3/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 1.1223 - root_mean_squared_error: 0.9680\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.93628\n",
      "80001/80001 [==============================] - 326s 4ms/step - loss: 1.1223 - root_mean_squared_error: 0.9680 - val_loss: 1.0988 - val_root_mean_squared_error: 0.9598\n",
      "Epoch 4/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.1163 - root_mean_squared_error: 0.9687\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.93628\n",
      "80001/80001 [==============================] - 325s 4ms/step - loss: 1.1163 - root_mean_squared_error: 0.9687 - val_loss: 1.1430 - val_root_mean_squared_error: 0.9899\n",
      "Epoch 5/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.1122 - root_mean_squared_error: 0.9704\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.93628\n",
      "80001/80001 [==============================] - 322s 4ms/step - loss: 1.1122 - root_mean_squared_error: 0.9704 - val_loss: 1.0445 - val_root_mean_squared_error: 0.9396\n",
      "200002/200002 [==============================] - 122s 609us/step - loss: 1.0445 - root_mean_squared_error: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 19:04:47,912] Trial 38 finished with value: 0.930830717086792 and parameters: {'hidden_units': 140, 'learning_rate': 0.0442730366823337, 'dropout_1': 0.11504616040348527, 'dropout_2': 0.2107341368439454}. Best is trial 34 with value: 0.9028832316398621.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80314\n",
      "Epoch 1/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.2319 - root_mean_squared_error: 1.0564\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 1.05825, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 327s 4ms/step - loss: 1.2319 - root_mean_squared_error: 1.0564 - val_loss: 1.1235 - val_root_mean_squared_error: 1.0582\n",
      "Epoch 2/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.1471 - root_mean_squared_error: 1.0616\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 1.05825\n",
      "80001/80001 [==============================] - 318s 4ms/step - loss: 1.1472 - root_mean_squared_error: 1.0616 - val_loss: 1.1267 - val_root_mean_squared_error: 1.0598\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.1263 - root_mean_squared_error: 1.0593\n",
      "Epoch 3: val_root_mean_squared_error improved from 1.05825 to 1.05777, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 334s 4ms/step - loss: 1.1263 - root_mean_squared_error: 1.0593 - val_loss: 1.1226 - val_root_mean_squared_error: 1.0578\n",
      "Epoch 4/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.1284 - root_mean_squared_error: 1.0595\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 1.05777\n",
      "80001/80001 [==============================] - 341s 4ms/step - loss: 1.1284 - root_mean_squared_error: 1.0595 - val_loss: 1.1273 - val_root_mean_squared_error: 1.0599\n",
      "Epoch 5/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.1256 - root_mean_squared_error: 1.0592\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 1.05777\n",
      "80001/80001 [==============================] - 347s 4ms/step - loss: 1.1256 - root_mean_squared_error: 1.0592 - val_loss: 1.1233 - val_root_mean_squared_error: 1.0581\n",
      "200002/200002 [==============================] - 129s 645us/step - loss: 1.1232 - root_mean_squared_error: 1.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 19:34:54,818] Trial 39 finished with value: 1.0494245290756226 and parameters: {'hidden_units': 98, 'learning_rate': 0.097451489018503, 'dropout_1': 0.14437817777425752, 'dropout_2': 0.2368245384576399}. Best is trial 34 with value: 0.9028832316398621.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80259\n",
      "Epoch 1/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0165 - root_mean_squared_error: 0.9393\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91279, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 394s 5ms/step - loss: 1.0165 - root_mean_squared_error: 0.9393 - val_loss: 0.9642 - val_root_mean_squared_error: 0.9128\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 0.9938 - root_mean_squared_error: 0.9282\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.91279\n",
      "80001/80001 [==============================] - 362s 5ms/step - loss: 0.9938 - root_mean_squared_error: 0.9282 - val_loss: 0.9658 - val_root_mean_squared_error: 0.9131\n",
      "Epoch 3/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 0.9895 - root_mean_squared_error: 0.9263\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.91279 to 0.90988, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 334s 4ms/step - loss: 0.9895 - root_mean_squared_error: 0.9263 - val_loss: 0.9684 - val_root_mean_squared_error: 0.9099\n",
      "Epoch 4/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 0.9867 - root_mean_squared_error: 0.9255\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90988\n",
      "80001/80001 [==============================] - 331s 4ms/step - loss: 0.9867 - root_mean_squared_error: 0.9255 - val_loss: 0.9894 - val_root_mean_squared_error: 0.9292\n",
      "Epoch 5/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 0.9858 - root_mean_squared_error: 0.9252\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90988\n",
      "80001/80001 [==============================] - 329s 4ms/step - loss: 0.9858 - root_mean_squared_error: 0.9252 - val_loss: 0.9680 - val_root_mean_squared_error: 0.9116\n",
      "200002/200002 [==============================] - 122s 610us/step - loss: 0.9680 - root_mean_squared_error: 0.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 20:06:19,053] Trial 40 finished with value: 0.9017379879951477 and parameters: {'hidden_units': 181, 'learning_rate': 0.015439074897551173, 'dropout_1': 0.11320841679200497, 'dropout_2': 0.17399228174482215}. Best is trial 40 with value: 0.9017379879951477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80241\n",
      "Epoch 1/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 1.0150 - root_mean_squared_error: 0.9391\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91684, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 341s 4ms/step - loss: 1.0150 - root_mean_squared_error: 0.9391 - val_loss: 0.9665 - val_root_mean_squared_error: 0.9168\n",
      "Epoch 2/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 0.9921 - root_mean_squared_error: 0.9285\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91684 to 0.91218, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 330s 4ms/step - loss: 0.9922 - root_mean_squared_error: 0.9285 - val_loss: 0.9693 - val_root_mean_squared_error: 0.9122\n",
      "Epoch 3/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9878 - root_mean_squared_error: 0.9266\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.91218\n",
      "80001/80001 [==============================] - 344s 4ms/step - loss: 0.9878 - root_mean_squared_error: 0.9266 - val_loss: 0.9747 - val_root_mean_squared_error: 0.9169\n",
      "Epoch 4/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9851 - root_mean_squared_error: 0.9256\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.91218\n",
      "80001/80001 [==============================] - 359s 4ms/step - loss: 0.9851 - root_mean_squared_error: 0.9256 - val_loss: 0.9517 - val_root_mean_squared_error: 0.9149\n",
      "Epoch 5/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 0.9823 - root_mean_squared_error: 0.9249\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91218\n",
      "80001/80001 [==============================] - 352s 4ms/step - loss: 0.9823 - root_mean_squared_error: 0.9249 - val_loss: 0.9860 - val_root_mean_squared_error: 0.9252\n",
      "200002/200002 [==============================] - 124s 621us/step - loss: 0.9860 - root_mean_squared_error: 0.9173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 20:37:21,575] Trial 41 finished with value: 0.9173111915588379 and parameters: {'hidden_units': 182, 'learning_rate': 0.01518049504988966, 'dropout_1': 0.11123383474614454, 'dropout_2': 0.1672231197725469}. Best is trial 40 with value: 0.9017379879951477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80213\n",
      "Epoch 1/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0741 - root_mean_squared_error: 0.9539\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92980, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 341s 4ms/step - loss: 1.0741 - root_mean_squared_error: 0.9539 - val_loss: 1.0398 - val_root_mean_squared_error: 0.9298\n",
      "Epoch 2/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0483 - root_mean_squared_error: 0.9442\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92980 to 0.92497, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 338s 4ms/step - loss: 1.0483 - root_mean_squared_error: 0.9442 - val_loss: 1.0201 - val_root_mean_squared_error: 0.9250\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 1.0409 - root_mean_squared_error: 0.9436\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.92497\n",
      "80001/80001 [==============================] - 342s 4ms/step - loss: 1.0409 - root_mean_squared_error: 0.9436 - val_loss: 1.0278 - val_root_mean_squared_error: 0.9311\n",
      "Epoch 4/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0362 - root_mean_squared_error: 0.9436\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.92497 to 0.92109, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 368s 5ms/step - loss: 1.0362 - root_mean_squared_error: 0.9436 - val_loss: 0.9843 - val_root_mean_squared_error: 0.9211\n",
      "Epoch 5/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 1.0358 - root_mean_squared_error: 0.9442\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.92109\n",
      "80001/80001 [==============================] - 373s 5ms/step - loss: 1.0358 - root_mean_squared_error: 0.9442 - val_loss: 1.0011 - val_root_mean_squared_error: 0.9236\n",
      "200002/200002 [==============================] - 128s 642us/step - loss: 1.0011 - root_mean_squared_error: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 21:09:04,245] Trial 42 finished with value: 0.913659930229187 and parameters: {'hidden_units': 198, 'learning_rate': 0.02285419122998698, 'dropout_1': 0.14256713497672688, 'dropout_2': 0.19143642295277824}. Best is trial 40 with value: 0.9017379879951477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80148\n",
      "Epoch 1/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.1172 - root_mean_squared_error: 0.9613\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.94251, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 339s 4ms/step - loss: 1.1172 - root_mean_squared_error: 0.9613 - val_loss: 1.0958 - val_root_mean_squared_error: 0.9425\n",
      "Epoch 2/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.0815 - root_mean_squared_error: 0.9513\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.94251 to 0.93171, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 361s 5ms/step - loss: 1.0816 - root_mean_squared_error: 0.9513 - val_loss: 1.0542 - val_root_mean_squared_error: 0.9317\n",
      "Epoch 3/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 1.0745 - root_mean_squared_error: 0.9495\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.93171 to 0.92836, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 371s 5ms/step - loss: 1.0745 - root_mean_squared_error: 0.9495 - val_loss: 1.0185 - val_root_mean_squared_error: 0.9284\n",
      "Epoch 4/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.0685 - root_mean_squared_error: 0.9503\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.92836\n",
      "80001/80001 [==============================] - 350s 4ms/step - loss: 1.0685 - root_mean_squared_error: 0.9503 - val_loss: 1.0498 - val_root_mean_squared_error: 0.9440\n",
      "Epoch 5/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 1.0613 - root_mean_squared_error: 0.9520\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.92836\n",
      "80001/80001 [==============================] - 365s 5ms/step - loss: 1.0613 - root_mean_squared_error: 0.9520 - val_loss: 1.0305 - val_root_mean_squared_error: 0.9397\n",
      "200002/200002 [==============================] - 134s 670us/step - loss: 1.0305 - root_mean_squared_error: 0.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 21:41:23,208] Trial 43 finished with value: 0.9308684468269348 and parameters: {'hidden_units': 167, 'learning_rate': 0.032518686104386615, 'dropout_1': 0.1179414597528663, 'dropout_2': 0.16667682996059371}. Best is trial 40 with value: 0.9017379879951477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80258\n",
      "Epoch 1/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.0154 - root_mean_squared_error: 0.9391\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91443, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 349s 4ms/step - loss: 1.0154 - root_mean_squared_error: 0.9391 - val_loss: 0.9685 - val_root_mean_squared_error: 0.9144\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9926 - root_mean_squared_error: 0.9286\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91443 to 0.91077, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 331s 4ms/step - loss: 0.9926 - root_mean_squared_error: 0.9286 - val_loss: 0.9672 - val_root_mean_squared_error: 0.9108\n",
      "Epoch 3/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9860 - root_mean_squared_error: 0.9269\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.91077\n",
      "80001/80001 [==============================] - 333s 4ms/step - loss: 0.9860 - root_mean_squared_error: 0.9269 - val_loss: 0.9545 - val_root_mean_squared_error: 0.9136\n",
      "Epoch 4/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9813 - root_mean_squared_error: 0.9261\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.91077\n",
      "80001/80001 [==============================] - 330s 4ms/step - loss: 0.9813 - root_mean_squared_error: 0.9261 - val_loss: 0.9491 - val_root_mean_squared_error: 0.9111\n",
      "Epoch 5/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 0.9808 - root_mean_squared_error: 0.9257\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.91077 to 0.90857, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 326s 4ms/step - loss: 0.9808 - root_mean_squared_error: 0.9257 - val_loss: 0.9496 - val_root_mean_squared_error: 0.9086\n",
      "200002/200002 [==============================] - 143s 713us/step - loss: 0.9496 - root_mean_squared_error: 0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 22:11:52,690] Trial 44 finished with value: 0.898984968662262 and parameters: {'hidden_units': 138, 'learning_rate': 0.015893533005819128, 'dropout_1': 0.10050169140675555, 'dropout_2': 0.1956424453135526}. Best is trial 44 with value: 0.898984968662262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80307\n",
      "Epoch 1/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0045 - root_mean_squared_error: 0.9363\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91729, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 342s 4ms/step - loss: 1.0045 - root_mean_squared_error: 0.9363 - val_loss: 0.9660 - val_root_mean_squared_error: 0.9173\n",
      "Epoch 2/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 0.9830 - root_mean_squared_error: 0.9256\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91729 to 0.91522, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 335s 4ms/step - loss: 0.9830 - root_mean_squared_error: 0.9256 - val_loss: 0.9661 - val_root_mean_squared_error: 0.9152\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9800 - root_mean_squared_error: 0.9239\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.91522 to 0.90969, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 331s 4ms/step - loss: 0.9800 - root_mean_squared_error: 0.9239 - val_loss: 0.9429 - val_root_mean_squared_error: 0.9097\n",
      "Epoch 4/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 0.9777 - root_mean_squared_error: 0.9232\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90969\n",
      "80001/80001 [==============================] - 357s 4ms/step - loss: 0.9777 - root_mean_squared_error: 0.9232 - val_loss: 0.9762 - val_root_mean_squared_error: 0.9221\n",
      "Epoch 5/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9756 - root_mean_squared_error: 0.9229\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90969\n",
      "80001/80001 [==============================] - 357s 4ms/step - loss: 0.9756 - root_mean_squared_error: 0.9229 - val_loss: 0.9513 - val_root_mean_squared_error: 0.9127\n",
      "200002/200002 [==============================] - 132s 659us/step - loss: 0.9513 - root_mean_squared_error: 0.9034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 22:43:08,256] Trial 45 finished with value: 0.9034157395362854 and parameters: {'hidden_units': 72, 'learning_rate': 0.014640997285745232, 'dropout_1': 0.10067573375831627, 'dropout_2': 0.19493237736381}. Best is trial 44 with value: 0.898984968662262.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80348\n",
      "Epoch 1/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.1993 - root_mean_squared_error: 0.9875\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.95767, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 333s 4ms/step - loss: 1.1993 - root_mean_squared_error: 0.9875 - val_loss: 1.1019 - val_root_mean_squared_error: 0.9577\n",
      "Epoch 2/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.1751 - root_mean_squared_error: 0.9823\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.95767\n",
      "80001/80001 [==============================] - 353s 4ms/step - loss: 1.1751 - root_mean_squared_error: 0.9823 - val_loss: 1.1541 - val_root_mean_squared_error: 0.9708\n",
      "Epoch 3/5\n",
      "11709/80001 [===>..........................] - ETA: 5:53 - loss: 1.1655 - root_mean_squared_error: 0.9842"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    # direction=\"maximize\"\n",
    "    direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241m.\u001b[39mbest_trial\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(trial\u001b[38;5;241m.\u001b[39mvalue))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(trial\u001b[38;5;241m.\u001b[39mparams))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "\n",
    "print(\"Accuracy: {}\".format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study, params=[\"hidden_units\", \"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/client/session.py:1769: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.layers import Input, Embedding, Flatten, Dropout, Concatenate, Dense, Activation, Lambda\n",
    "    from keras import Model\n",
    "    from keras.regularizers import l2\n",
    "    from keras.optimizers import Adam\n",
    "    \n",
    "    \n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 125, 145)\n",
    "    learning_rate = 0.015#trial.suggest_float(\"learning_rate\", 1e-2, 1e1, log=True)\n",
    "    dropout_1 = 0.1#trial.suggest_float(\"dropout_1\", 0.1, 0.4, log=True)\n",
    "    dropout_2 = 0.2#trial.suggest_float(\"dropout_2\", 0.1, 0.5, log=True)\n",
    "\n",
    "    ratings_train, ratings_val = train_test_split(ratings, test_size=0.2)\n",
    "    n_users = int(ratings.userId.nunique())\n",
    "    n_movies = int(ratings.movieId.nunique())\n",
    "    n_users_train = int(ratings_train.userId.nunique())\n",
    "    n_movies_train = int(ratings_train.movieId.nunique())\n",
    "    print(n_users, n_movies, n_users_train, n_movies_train)\n",
    "    max_rating = ratings_train['rating'].max()\n",
    "    min_rating = ratings_train['rating'].min()\n",
    "    av_rating = ratings_train['rating'].mean()\n",
    "    max_rating, min_rating, av_rating\n",
    "\n",
    "\n",
    "    movie_embedding_regularizer = 0.001\n",
    "    #mlflow.log_param(\"movie_embedding_regularizer_l2\", movie_embedding_regularizer)\n",
    "\n",
    "    movie_input = Input(shape=[1],name='Item')\n",
    "    movie_embedding = Embedding(n_movies + 1, n_latent_factors_movie, name='Movie-Embedding', embeddings_regularizer = l2(movie_embedding_regularizer))(movie_input)\n",
    "    movie_vec = Flatten(name='FlattenMovies')(movie_embedding)\n",
    "    movie_vec = Dropout(dropout_1)(movie_vec)\n",
    "\n",
    "    user_input = Input(shape=[1],name='User')\n",
    "    user_vec = Flatten(name='FlattenUsers')(Embedding(n_users + 1, \n",
    "    n_latent_factors_user,name='User-Embedding')(user_input))\n",
    "    user_vec = Dropout(dropout_1)(user_vec)\n",
    "\n",
    "    concat = Concatenate(name='Concat')([movie_vec, user_vec])\n",
    "    concat = Dropout(dropout_1)(concat)\n",
    "\n",
    "    x = Dense(hidden_units,name='FullyConnected-1', activation='relu')(concat)\n",
    "    x = Dropout(dropout_2)(x)\n",
    "    # x = Dense(50,name='FullyConnected-1', activation='relu')(concat)\n",
    "    # x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "    ## Se pueden sacar las siguientes dos lineas para no forzar a sigmoidea\n",
    "    x = Dense(1, activation='sigmoid',name='Activation')(x)\n",
    "    x = Lambda(lambda z: (max_rating - min_rating) * z + min_rating)(x)\n",
    "    ##\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='weights2.hdf5', verbose=1, save_best_only=True, monitor='val_root_mean_squared_error')\n",
    "\n",
    "    import keras.backend as K \n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n",
    "    model = Model([user_input, movie_input], x)\n",
    "    lr = 0.001\n",
    "    model.compile(Adam(learning_rate=learning_rate), 'mean_squared_error', metrics=[root_mean_squared_error])\n",
    "    #mlflow.log_param(\"lr\", lr)\n",
    "    batch_size = 320\n",
    "    epochs = 5\n",
    "    #mlflow.log_param(\"batch_size\", batch_size)\n",
    "    #mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "    history = model.fit([ratings_train.userId, ratings_train.movieId], \n",
    "                        ratings_train.rating, \n",
    "                        validation_data=([ratings_val.userId, ratings_val.movieId], ratings_val.rating), \n",
    "                        batch_size = batch_size,\n",
    "                        callbacks = [checkpointer],\n",
    "                        epochs=epochs, verbose=1)\n",
    "    val_loss, rmse = np.array(model.evaluate([ratings_val.userId, ratings_val.movieId], ratings_val.rating))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-25 23:13:02,281] A new study created in memory with name: no-name-2241cff9-8df2-43ef-96aa-f84fe224fcb4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80245\n",
      "Epoch 1/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 1.0109 - root_mean_squared_error: 0.9382\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91946, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 434s 5ms/step - loss: 1.0109 - root_mean_squared_error: 0.9382 - val_loss: 0.9770 - val_root_mean_squared_error: 0.9195\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9882 - root_mean_squared_error: 0.9272\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91946 to 0.90972, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 613s 8ms/step - loss: 0.9882 - root_mean_squared_error: 0.9272 - val_loss: 0.9569 - val_root_mean_squared_error: 0.9097\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9845 - root_mean_squared_error: 0.9253\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.90972\n",
      "80001/80001 [==============================] - 621s 8ms/step - loss: 0.9845 - root_mean_squared_error: 0.9253 - val_loss: 0.9673 - val_root_mean_squared_error: 0.9156\n",
      "Epoch 4/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 0.9816 - root_mean_squared_error: 0.9247\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90972\n",
      "80001/80001 [==============================] - 598s 7ms/step - loss: 0.9816 - root_mean_squared_error: 0.9247 - val_loss: 0.9625 - val_root_mean_squared_error: 0.9134\n",
      "Epoch 5/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9790 - root_mean_squared_error: 0.9245\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.90972 to 0.90433, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 608s 8ms/step - loss: 0.9790 - root_mean_squared_error: 0.9245 - val_loss: 0.9355 - val_root_mean_squared_error: 0.9043\n",
      "200002/200002 [==============================] - 386s 2ms/step - loss: 0.9355 - root_mean_squared_error: 0.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 00:07:42,855] Trial 0 finished with value: 0.8949152827262878 and parameters: {'hidden_units': 126}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80242\n",
      "Epoch 1/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.0063 - root_mean_squared_error: 0.9371\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91388, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 449s 6ms/step - loss: 1.0063 - root_mean_squared_error: 0.9371 - val_loss: 0.9585 - val_root_mean_squared_error: 0.9139\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9840 - root_mean_squared_error: 0.9262\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91388 to 0.91373, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 508s 6ms/step - loss: 0.9840 - root_mean_squared_error: 0.9262 - val_loss: 0.9725 - val_root_mean_squared_error: 0.9137\n",
      "Epoch 3/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 0.9818 - root_mean_squared_error: 0.9243\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.91373 to 0.91023, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 591s 7ms/step - loss: 0.9818 - root_mean_squared_error: 0.9243 - val_loss: 0.9554 - val_root_mean_squared_error: 0.9102\n",
      "Epoch 4/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 0.9803 - root_mean_squared_error: 0.9236\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.91023\n",
      "80001/80001 [==============================] - 582s 7ms/step - loss: 0.9803 - root_mean_squared_error: 0.9236 - val_loss: 0.9506 - val_root_mean_squared_error: 0.9135\n",
      "Epoch 5/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9764 - root_mean_squared_error: 0.9236\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91023\n",
      "80001/80001 [==============================] - 589s 7ms/step - loss: 0.9764 - root_mean_squared_error: 0.9236 - val_loss: 0.9495 - val_root_mean_squared_error: 0.9103\n",
      "200002/200002 [==============================] - 383s 2ms/step - loss: 0.9496 - root_mean_squared_error: 0.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 00:59:53,486] Trial 1 finished with value: 0.9015427231788635 and parameters: {'hidden_units': 132}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80142\n",
      "Epoch 1/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0080 - root_mean_squared_error: 0.9377\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91823, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 498s 6ms/step - loss: 1.0080 - root_mean_squared_error: 0.9377 - val_loss: 0.9636 - val_root_mean_squared_error: 0.9182\n",
      "Epoch 2/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 0.9876 - root_mean_squared_error: 0.9274\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91823 to 0.91434, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 463s 6ms/step - loss: 0.9876 - root_mean_squared_error: 0.9274 - val_loss: 0.9568 - val_root_mean_squared_error: 0.9143\n",
      "Epoch 3/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9825 - root_mean_squared_error: 0.9257\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.91434 to 0.90991, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 632s 8ms/step - loss: 0.9825 - root_mean_squared_error: 0.9257 - val_loss: 0.9629 - val_root_mean_squared_error: 0.9099\n",
      "Epoch 4/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9792 - root_mean_squared_error: 0.9248\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90991\n",
      "80001/80001 [==============================] - 620s 8ms/step - loss: 0.9792 - root_mean_squared_error: 0.9248 - val_loss: 0.9528 - val_root_mean_squared_error: 0.9142\n",
      "Epoch 5/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 0.9770 - root_mean_squared_error: 0.9244\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90991\n",
      "80001/80001 [==============================] - 620s 8ms/step - loss: 0.9770 - root_mean_squared_error: 0.9244 - val_loss: 0.9602 - val_root_mean_squared_error: 0.9113\n",
      "200002/200002 [==============================] - 385s 2ms/step - loss: 0.9602 - root_mean_squared_error: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 01:53:58,870] Trial 2 finished with value: 0.9017906188964844 and parameters: {'hidden_units': 143}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80047\n",
      "Epoch 1/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 1.0101 - root_mean_squared_error: 0.9374\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91425, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 445s 6ms/step - loss: 1.0101 - root_mean_squared_error: 0.9374 - val_loss: 0.9723 - val_root_mean_squared_error: 0.9142\n",
      "Epoch 2/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 0.9871 - root_mean_squared_error: 0.9268\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.91425\n",
      "80001/80001 [==============================] - 337s 4ms/step - loss: 0.9871 - root_mean_squared_error: 0.9268 - val_loss: 0.9655 - val_root_mean_squared_error: 0.9144\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9829 - root_mean_squared_error: 0.9245\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.91425 to 0.90857, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9829 - root_mean_squared_error: 0.9245 - val_loss: 0.9568 - val_root_mean_squared_error: 0.9086\n",
      "Epoch 4/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 0.9797 - root_mean_squared_error: 0.9238\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90857\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 0.9797 - root_mean_squared_error: 0.9238 - val_loss: 0.9654 - val_root_mean_squared_error: 0.9162\n",
      "Epoch 5/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 0.9774 - root_mean_squared_error: 0.9235\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90857\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 0.9774 - root_mean_squared_error: 0.9235 - val_loss: 0.9547 - val_root_mean_squared_error: 0.9140\n",
      "200002/200002 [==============================] - 119s 592us/step - loss: 0.9547 - root_mean_squared_error: 0.9037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 02:24:59,208] Trial 3 finished with value: 0.9037411212921143 and parameters: {'hidden_units': 142}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80297\n",
      "Epoch 1/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 1.0095 - root_mean_squared_error: 0.9379\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91570, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 318s 4ms/step - loss: 1.0095 - root_mean_squared_error: 0.9379 - val_loss: 0.9701 - val_root_mean_squared_error: 0.9157\n",
      "Epoch 2/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 0.9886 - root_mean_squared_error: 0.9281\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91570 to 0.91066, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 0.9886 - root_mean_squared_error: 0.9281 - val_loss: 0.9447 - val_root_mean_squared_error: 0.9107\n",
      "Epoch 3/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 0.9823 - root_mean_squared_error: 0.9262\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.91066 to 0.90864, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9823 - root_mean_squared_error: 0.9262 - val_loss: 0.9331 - val_root_mean_squared_error: 0.9086\n",
      "Epoch 4/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 0.9777 - root_mean_squared_error: 0.9251\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90864\n",
      "80001/80001 [==============================] - 316s 4ms/step - loss: 0.9777 - root_mean_squared_error: 0.9251 - val_loss: 0.9552 - val_root_mean_squared_error: 0.9161\n",
      "Epoch 5/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9742 - root_mean_squared_error: 0.9247\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90864\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9742 - root_mean_squared_error: 0.9247 - val_loss: 0.9619 - val_root_mean_squared_error: 0.9215\n",
      "200002/200002 [==============================] - 119s 593us/step - loss: 0.9619 - root_mean_squared_error: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 02:53:22,037] Trial 4 finished with value: 0.9121958017349243 and parameters: {'hidden_units': 139}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80155\n",
      "Epoch 1/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.0090 - root_mean_squared_error: 0.9374\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91657, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 1.0090 - root_mean_squared_error: 0.9374 - val_loss: 0.9731 - val_root_mean_squared_error: 0.9166\n",
      "Epoch 2/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 0.9870 - root_mean_squared_error: 0.9263\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91657 to 0.91270, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9870 - root_mean_squared_error: 0.9263 - val_loss: 0.9586 - val_root_mean_squared_error: 0.9127\n",
      "Epoch 3/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 0.9827 - root_mean_squared_error: 0.9244\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.91270\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 0.9827 - root_mean_squared_error: 0.9244 - val_loss: 0.9636 - val_root_mean_squared_error: 0.9153\n",
      "Epoch 4/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 0.9768 - root_mean_squared_error: 0.9239\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.91270 to 0.90777, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9768 - root_mean_squared_error: 0.9239 - val_loss: 0.9540 - val_root_mean_squared_error: 0.9078\n",
      "Epoch 5/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 0.9769 - root_mean_squared_error: 0.9236\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90777\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9769 - root_mean_squared_error: 0.9236 - val_loss: 0.9398 - val_root_mean_squared_error: 0.9098\n",
      "200002/200002 [==============================] - 119s 596us/step - loss: 0.9398 - root_mean_squared_error: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 03:21:35,070] Trial 5 finished with value: 0.900510311126709 and parameters: {'hidden_units': 134}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80287\n",
      "Epoch 1/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 1.0098 - root_mean_squared_error: 0.9379\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91367, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 1.0098 - root_mean_squared_error: 0.9379 - val_loss: 0.9635 - val_root_mean_squared_error: 0.9137\n",
      "Epoch 2/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9870 - root_mean_squared_error: 0.9276\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.91367\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9870 - root_mean_squared_error: 0.9276 - val_loss: 0.9654 - val_root_mean_squared_error: 0.9178\n",
      "Epoch 3/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 0.9816 - root_mean_squared_error: 0.9258\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.91367 to 0.91148, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 0.9816 - root_mean_squared_error: 0.9258 - val_loss: 0.9591 - val_root_mean_squared_error: 0.9115\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 0.9763 - root_mean_squared_error: 0.9251\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.91148\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9763 - root_mean_squared_error: 0.9251 - val_loss: 0.9627 - val_root_mean_squared_error: 0.9210\n",
      "Epoch 5/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 0.9767 - root_mean_squared_error: 0.9246\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91148\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9767 - root_mean_squared_error: 0.9246 - val_loss: 0.9706 - val_root_mean_squared_error: 0.9168\n",
      "200002/200002 [==============================] - 120s 599us/step - loss: 0.9706 - root_mean_squared_error: 0.9082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 03:49:52,446] Trial 6 finished with value: 0.9081943035125732 and parameters: {'hidden_units': 133}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80223\n",
      "Epoch 1/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 1.0069 - root_mean_squared_error: 0.9373\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91117, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 1.0069 - root_mean_squared_error: 0.9373 - val_loss: 0.9649 - val_root_mean_squared_error: 0.9112\n",
      "Epoch 2/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 0.9846 - root_mean_squared_error: 0.9262\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.91117\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 0.9846 - root_mean_squared_error: 0.9262 - val_loss: 0.9589 - val_root_mean_squared_error: 0.9126\n",
      "Epoch 3/5\n",
      "79997/80001 [============================>.] - ETA: 0s - loss: 0.9800 - root_mean_squared_error: 0.9244\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.91117 to 0.90992, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 0.9800 - root_mean_squared_error: 0.9244 - val_loss: 0.9516 - val_root_mean_squared_error: 0.9099\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 0.9771 - root_mean_squared_error: 0.9237\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90992\n",
      "80001/80001 [==============================] - 311s 4ms/step - loss: 0.9771 - root_mean_squared_error: 0.9237 - val_loss: 0.9539 - val_root_mean_squared_error: 0.9106\n",
      "Epoch 5/5\n",
      "79992/80001 [============================>.] - ETA: 0s - loss: 0.9777 - root_mean_squared_error: 0.9232\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.90992 to 0.90696, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 312s 4ms/step - loss: 0.9777 - root_mean_squared_error: 0.9232 - val_loss: 0.9446 - val_root_mean_squared_error: 0.9070\n",
      "200002/200002 [==============================] - 120s 598us/step - loss: 0.9446 - root_mean_squared_error: 0.8975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 04:18:00,085] Trial 7 finished with value: 0.8974943161010742 and parameters: {'hidden_units': 125}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80212\n",
      "Epoch 1/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 1.0084 - root_mean_squared_error: 0.9376\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92037, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 316s 4ms/step - loss: 1.0084 - root_mean_squared_error: 0.9376 - val_loss: 0.9729 - val_root_mean_squared_error: 0.9204\n",
      "Epoch 2/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9859 - root_mean_squared_error: 0.9267\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.92037 to 0.90868, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9859 - root_mean_squared_error: 0.9267 - val_loss: 0.9616 - val_root_mean_squared_error: 0.9087\n",
      "Epoch 3/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 0.9823 - root_mean_squared_error: 0.9244\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.90868\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9823 - root_mean_squared_error: 0.9244 - val_loss: 0.9626 - val_root_mean_squared_error: 0.9146\n",
      "Epoch 4/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 0.9783 - root_mean_squared_error: 0.9238\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.90868 to 0.90743, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9783 - root_mean_squared_error: 0.9238 - val_loss: 0.9434 - val_root_mean_squared_error: 0.9074\n",
      "Epoch 5/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9738 - root_mean_squared_error: 0.9236\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90743\n",
      "80001/80001 [==============================] - 316s 4ms/step - loss: 0.9738 - root_mean_squared_error: 0.9236 - val_loss: 0.9471 - val_root_mean_squared_error: 0.9090\n",
      "200002/200002 [==============================] - 120s 602us/step - loss: 0.9471 - root_mean_squared_error: 0.8995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 04:46:23,220] Trial 8 finished with value: 0.8995462656021118 and parameters: {'hidden_units': 136}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80246\n",
      "Epoch 1/5\n",
      "79995/80001 [============================>.] - ETA: 0s - loss: 1.0085 - root_mean_squared_error: 0.9378\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.92273, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 316s 4ms/step - loss: 1.0085 - root_mean_squared_error: 0.9378 - val_loss: 0.9853 - val_root_mean_squared_error: 0.9227\n",
      "Epoch 2/5\n",
      "79993/80001 [============================>.] - ETA: 0s - loss: 0.9890 - root_mean_squared_error: 0.9280\n",
      "Epoch 2: val_root_mean_squared_error did not improve from 0.92273\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9890 - root_mean_squared_error: 0.9280 - val_loss: 0.9821 - val_root_mean_squared_error: 0.9231\n",
      "Epoch 3/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 0.9837 - root_mean_squared_error: 0.9262\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.92273 to 0.91308, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9837 - root_mean_squared_error: 0.9262 - val_loss: 0.9618 - val_root_mean_squared_error: 0.9131\n",
      "Epoch 4/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 0.9783 - root_mean_squared_error: 0.9252\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.91308 to 0.91222, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9783 - root_mean_squared_error: 0.9252 - val_loss: 0.9676 - val_root_mean_squared_error: 0.9122\n",
      "Epoch 5/5\n",
      "79991/80001 [============================>.] - ETA: 0s - loss: 0.9743 - root_mean_squared_error: 0.9247\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.91222\n",
      "80001/80001 [==============================] - 318s 4ms/step - loss: 0.9743 - root_mean_squared_error: 0.9247 - val_loss: 0.9566 - val_root_mean_squared_error: 0.9157\n",
      "200002/200002 [==============================] - 118s 591us/step - loss: 0.9566 - root_mean_squared_error: 0.9069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 05:14:45,509] Trial 9 finished with value: 0.9069241881370544 and parameters: {'hidden_units': 135}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80220\n",
      "Epoch 1/5\n",
      "79989/80001 [============================>.] - ETA: 0s - loss: 1.0068 - root_mean_squared_error: 0.9372\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91288, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 1.0068 - root_mean_squared_error: 0.9372 - val_loss: 0.9632 - val_root_mean_squared_error: 0.9129\n",
      "Epoch 2/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9860 - root_mean_squared_error: 0.9267\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91288 to 0.90971, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9860 - root_mean_squared_error: 0.9267 - val_loss: 0.9572 - val_root_mean_squared_error: 0.9097\n",
      "Epoch 3/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 0.9818 - root_mean_squared_error: 0.9250\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.90971 to 0.90768, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 0.9818 - root_mean_squared_error: 0.9250 - val_loss: 0.9577 - val_root_mean_squared_error: 0.9077\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 0.9802 - root_mean_squared_error: 0.9241\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90768\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 0.9802 - root_mean_squared_error: 0.9241 - val_loss: 0.9565 - val_root_mean_squared_error: 0.9171\n",
      "Epoch 5/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 0.9768 - root_mean_squared_error: 0.9241\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90768\n",
      "80001/80001 [==============================] - 315s 4ms/step - loss: 0.9768 - root_mean_squared_error: 0.9241 - val_loss: 0.9628 - val_root_mean_squared_error: 0.9151\n",
      "200002/200002 [==============================] - 122s 608us/step - loss: 0.9628 - root_mean_squared_error: 0.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 05:43:09,802] Trial 10 finished with value: 0.9066080451011658 and parameters: {'hidden_units': 125}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80204\n",
      "Epoch 1/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 1.0078 - root_mean_squared_error: 0.9376\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91618, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 316s 4ms/step - loss: 1.0078 - root_mean_squared_error: 0.9376 - val_loss: 0.9593 - val_root_mean_squared_error: 0.9162\n",
      "Epoch 2/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 0.9859 - root_mean_squared_error: 0.9266\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91618 to 0.91246, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9859 - root_mean_squared_error: 0.9267 - val_loss: 0.9446 - val_root_mean_squared_error: 0.9125\n",
      "Epoch 3/5\n",
      "79999/80001 [============================>.] - ETA: 0s - loss: 0.9821 - root_mean_squared_error: 0.9251\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.91246\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9821 - root_mean_squared_error: 0.9251 - val_loss: 0.9604 - val_root_mean_squared_error: 0.9209\n",
      "Epoch 4/5\n",
      "79996/80001 [============================>.] - ETA: 0s - loss: 0.9785 - root_mean_squared_error: 0.9244\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.91246 to 0.90849, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 313s 4ms/step - loss: 0.9785 - root_mean_squared_error: 0.9244 - val_loss: 0.9507 - val_root_mean_squared_error: 0.9085\n",
      "Epoch 5/5\n",
      "79994/80001 [============================>.] - ETA: 0s - loss: 0.9776 - root_mean_squared_error: 0.9243\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90849\n",
      "80001/80001 [==============================] - 314s 4ms/step - loss: 0.9776 - root_mean_squared_error: 0.9243 - val_loss: 0.9605 - val_root_mean_squared_error: 0.9157\n",
      "200002/200002 [==============================] - 120s 599us/step - loss: 0.9605 - root_mean_squared_error: 0.9054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 06:11:28,620] Trial 11 finished with value: 0.9054490923881531 and parameters: {'hidden_units': 125}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80281\n",
      "Epoch 1/5\n",
      "80000/80001 [============================>.] - ETA: 0s - loss: 1.0072 - root_mean_squared_error: 0.9372\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.91393, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 325s 4ms/step - loss: 1.0072 - root_mean_squared_error: 0.9372 - val_loss: 0.9711 - val_root_mean_squared_error: 0.9139\n",
      "Epoch 2/5\n",
      "79998/80001 [============================>.] - ETA: 0s - loss: 0.9861 - root_mean_squared_error: 0.9262\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.91393 to 0.90982, saving model to weights2.hdf5\n",
      "80001/80001 [==============================] - 323s 4ms/step - loss: 0.9861 - root_mean_squared_error: 0.9262 - val_loss: 0.9636 - val_root_mean_squared_error: 0.9098\n",
      "Epoch 3/5\n",
      "79990/80001 [============================>.] - ETA: 0s - loss: 0.9820 - root_mean_squared_error: 0.9243\n",
      "Epoch 3: val_root_mean_squared_error did not improve from 0.90982\n",
      "80001/80001 [==============================] - 353s 4ms/step - loss: 0.9820 - root_mean_squared_error: 0.9243 - val_loss: 0.9607 - val_root_mean_squared_error: 0.9116\n",
      "Epoch 4/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9793 - root_mean_squared_error: 0.9235\n",
      "Epoch 4: val_root_mean_squared_error did not improve from 0.90982\n",
      "80001/80001 [==============================] - 345s 4ms/step - loss: 0.9793 - root_mean_squared_error: 0.9235 - val_loss: 0.9689 - val_root_mean_squared_error: 0.9120\n",
      "Epoch 5/5\n",
      "80001/80001 [==============================] - ETA: 0s - loss: 0.9758 - root_mean_squared_error: 0.9235\n",
      "Epoch 5: val_root_mean_squared_error did not improve from 0.90982\n",
      "80001/80001 [==============================] - 973s 12ms/step - loss: 0.9758 - root_mean_squared_error: 0.9235 - val_loss: 0.9578 - val_root_mean_squared_error: 0.9132\n",
      "200002/200002 [==============================] - 137s 684us/step - loss: 0.9578 - root_mean_squared_error: 0.9030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 06:52:51,327] Trial 12 finished with value: 0.9029991030693054 and parameters: {'hidden_units': 128}. Best is trial 0 with value: 0.8949152827262878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200948 84432 200948 80196\n",
      "Epoch 1/5\n",
      "15863/80001 [====>.........................] - ETA: 4:39 - loss: 1.0482 - root_mean_squared_error: 0.9553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-11-26 06:54:14,622] Trial 13 failed with parameters: {'hidden_units': 129} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/7f/19f36bv57_72qpq3mfj1x6240000gn/T/ipykernel_18302/2477498198.py\", line 68, in objective\n",
      "    history = model.fit([ratings_train.userId, ratings_train.movieId],\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 912, in _call\n",
      "    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 134, in __call__\n",
      "    return concrete_function._call_flat(\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1745, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 378, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-26 06:54:14,636] Trial 13 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# direction=\"maximize\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[13], line 68\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     64\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#mlflow.log_param(\"batch_size\", batch_size)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#mlflow.log_param(\"epochs\", epochs)\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mratings_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muserId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmovieId\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mratings_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrating\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mratings_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muserId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmovieId\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrating\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m val_loss, rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model\u001b[38;5;241m.\u001b[39mevaluate([ratings_val\u001b[38;5;241m.\u001b[39muserId, ratings_val\u001b[38;5;241m.\u001b[39mmovieId], ratings_val\u001b[38;5;241m.\u001b[39mrating))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rmse\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    # direction=\"maximize\"\n",
    "    direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8949152827262878\n",
      "Best hyperparameters: {'hidden_units': 126}\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "\n",
    "print(\"RMSE: {}\".format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
