{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'userId'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7f/19f36bv57_72qpq3mfj1x6240000gn/T/ipykernel_49225/3627748497.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/scores.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/usuarios.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/peliculas.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tp_2/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'userId'"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('../data/scores.csv')\n",
    "df_users = pd.read_csv('../data/usuarios.csv')\n",
    "df_movies = pd.read_csv('../data/peliculas.csv')\n",
    "\n",
    "df_movies.loc[df_movies['IMDB URL'].isna(), 'IMDB URL'] = ''\n",
    "\n",
    "u_unique = ratings.user_id.unique()\n",
    "user2Idx = {o:i+1 for i,o in enumerate(u_unique)}\n",
    "\n",
    "m_unique = ratings.movie_id.unique()\n",
    "movie2Idx = {o:i+1 for i,o in enumerate(m_unique)}\n",
    "\n",
    "ratings.user_id = ratings.user_id.apply(lambda x: user2Idx[x])\n",
    "\n",
    "ratings.movie_id = ratings.movie_id.apply(lambda x: movie2Idx[x])\n",
    "\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ratings_train, ratings_val = train_test_split(ratings, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682 943 1649\n"
     ]
    }
   ],
   "source": [
    "n_users = int(ratings.user_id.nunique())\n",
    "n_movies = int(ratings.movie_id.nunique())\n",
    "n_users_train = int(ratings_train.user_id.nunique())\n",
    "n_movies_train = int(ratings_train.movie_id.nunique())\n",
    "print(n_users, n_movies, n_users_train, n_movies_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 3.5301875)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rating = ratings_train['rating'].max()\n",
    "min_rating = ratings_train['rating'].min()\n",
    "av_rating = ratings_train['rating'].mean()\n",
    "max_rating, min_rating, av_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/981061820529434616', creation_time=1730667820019, experiment_id='981061820529434616', last_update_time=1730667820019, lifecycle_stage='active', name='Neural Network', tags={}>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seteo del experimento\n",
    "experiment_name = \"Neural Network\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Flatten, Dropout, Concatenate, Dense, Activation, Lambda\n",
    "from keras import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run(run_name=\"Early Stoping + latent factor 5 (3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_latent_factors_user = 5\n",
    "mlflow.log_param(\"n_latent_factors_user\", n_latent_factors_user)\n",
    "n_latent_factors_movie = 5\n",
    "mlflow.log_param(\"n_latent_factors_movie\", n_latent_factors_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Item (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " User (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Movie-Embedding (Embedding)    (None, 1, 5)         8415        ['Item[0][0]']                   \n",
      "                                                                                                  \n",
      " User-Embedding (Embedding)     (None, 1, 5)         4720        ['User[0][0]']                   \n",
      "                                                                                                  \n",
      " FlattenMovies (Flatten)        (None, 5)            0           ['Movie-Embedding[0][0]']        \n",
      "                                                                                                  \n",
      " FlattenUsers (Flatten)         (None, 5)            0           ['User-Embedding[0][0]']         \n",
      "                                                                                                  \n",
      " Concat (Concatenate)           (None, 10)           0           ['FlattenMovies[0][0]',          \n",
      "                                                                  'FlattenUsers[0][0]']           \n",
      "                                                                                                  \n",
      " FullyConnected-1 (Dense)       (None, 50)           550         ['Concat[0][0]']                 \n",
      "                                                                                                  \n",
      " Activation (Dense)             (None, 1)            51          ['FullyConnected-1[0][0]']       \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 1)            0           ['Activation[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,736\n",
      "Trainable params: 13,736\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "movie_embedding_regularizer = 0.001\n",
    "mlflow.log_param(\"movie_embedding_regularizer_l2\", movie_embedding_regularizer)\n",
    "\n",
    "movie_input = Input(shape=[1],name='Item')\n",
    "movie_embedding = Embedding(n_movies + 1, n_latent_factors_movie, name='Movie-Embedding', embeddings_regularizer = l2(movie_embedding_regularizer))(movie_input)\n",
    "movie_vec = Flatten(name='FlattenMovies')(movie_embedding)\n",
    "#movie_vec = Dropout(0.2)(movie_vec)\n",
    "\n",
    "user_input = Input(shape=[1],name='User')\n",
    "user_vec = Flatten(name='FlattenUsers')(Embedding(n_users + 1, \n",
    "n_latent_factors_user,name='User-Embedding')(user_input))\n",
    "#user_vec = Dropout(0.2)(user_vec)\n",
    "\n",
    "concat = Concatenate(name='Concat')([movie_vec, user_vec])\n",
    "#concat = Dropout(0.2)(concat)\n",
    "\n",
    "x = Dense(50,name='FullyConnected-1', activation='relu')(concat)\n",
    "#x = Dropout(0.5)(x)\n",
    "# x = Dense(50,name='FullyConnected-1', activation='relu')(concat)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "## Se pueden sacar las siguientes dos lineas para no forzar a sigmoidea\n",
    "x = Dense(1, activation='sigmoid',name='Activation')(x)\n",
    "x = Lambda(lambda z: (max_rating - min_rating) * z + min_rating)(x)\n",
    "##\n",
    "\n",
    "model = Model([user_input, movie_input], x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K \n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "model.compile(Adam(learning_rate=lr), 'mean_squared_error', metrics=[root_mean_squared_error])\n",
    "mlflow.log_param(\"lr\", lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='weights1.hdf5', verbose=1, save_best_only=True, monitor='val_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "patience = 5\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "mlflow.log_param(\"early_stopping_patience\", patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "182/250 [====================>.........] - ETA: 0s - loss: 1.1827 - root_mean_squared_error: 1.0819\n",
      "Epoch 1: val_root_mean_squared_error improved from inf to 0.95237, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 1.1184 - root_mean_squared_error: 1.0508 - val_loss: 0.9165 - val_root_mean_squared_error: 0.9524\n",
      "Epoch 2/100\n",
      "200/250 [=======================>......] - ETA: 0s - loss: 0.8936 - root_mean_squared_error: 0.9390\n",
      "Epoch 2: val_root_mean_squared_error improved from 0.95237 to 0.93993, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8933 - root_mean_squared_error: 0.9388 - val_loss: 0.8951 - val_root_mean_squared_error: 0.9399\n",
      "Epoch 3/100\n",
      "205/250 [=======================>......] - ETA: 0s - loss: 0.8806 - root_mean_squared_error: 0.9314\n",
      "Epoch 3: val_root_mean_squared_error improved from 0.93993 to 0.93689, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8761 - root_mean_squared_error: 0.9290 - val_loss: 0.8902 - val_root_mean_squared_error: 0.9369\n",
      "Epoch 4/100\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 0.8684 - root_mean_squared_error: 0.9244\n",
      "Epoch 4: val_root_mean_squared_error improved from 0.93689 to 0.93594, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8710 - root_mean_squared_error: 0.9258 - val_loss: 0.8885 - val_root_mean_squared_error: 0.9359\n",
      "Epoch 5/100\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 0.8690 - root_mean_squared_error: 0.9248\n",
      "Epoch 5: val_root_mean_squared_error improved from 0.93594 to 0.93527, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8680 - root_mean_squared_error: 0.9243 - val_loss: 0.8873 - val_root_mean_squared_error: 0.9353\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8658 - root_mean_squared_error: 0.9233\n",
      "Epoch 6: val_root_mean_squared_error did not improve from 0.93527\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8658 - root_mean_squared_error: 0.9233 - val_loss: 0.8883 - val_root_mean_squared_error: 0.9358\n",
      "Epoch 7/100\n",
      "198/250 [======================>.......] - ETA: 0s - loss: 0.8644 - root_mean_squared_error: 0.9222\n",
      "Epoch 7: val_root_mean_squared_error improved from 0.93527 to 0.93420, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8632 - root_mean_squared_error: 0.9216 - val_loss: 0.8852 - val_root_mean_squared_error: 0.9342\n",
      "Epoch 8/100\n",
      "194/250 [======================>.......] - ETA: 0s - loss: 0.8594 - root_mean_squared_error: 0.9198\n",
      "Epoch 8: val_root_mean_squared_error improved from 0.93420 to 0.93174, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8592 - root_mean_squared_error: 0.9197 - val_loss: 0.8806 - val_root_mean_squared_error: 0.9317\n",
      "Epoch 9/100\n",
      "198/250 [======================>.......] - ETA: 0s - loss: 0.8495 - root_mean_squared_error: 0.9144\n",
      "Epoch 9: val_root_mean_squared_error improved from 0.93174 to 0.92906, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8529 - root_mean_squared_error: 0.9162 - val_loss: 0.8756 - val_root_mean_squared_error: 0.9291\n",
      "Epoch 10/100\n",
      "199/250 [======================>.......] - ETA: 0s - loss: 0.8423 - root_mean_squared_error: 0.9101\n",
      "Epoch 10: val_root_mean_squared_error improved from 0.92906 to 0.92765, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8453 - root_mean_squared_error: 0.9119 - val_loss: 0.8730 - val_root_mean_squared_error: 0.9277\n",
      "Epoch 11/100\n",
      "194/250 [======================>.......] - ETA: 0s - loss: 0.8359 - root_mean_squared_error: 0.9069\n",
      "Epoch 11: val_root_mean_squared_error improved from 0.92765 to 0.92642, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8385 - root_mean_squared_error: 0.9084 - val_loss: 0.8709 - val_root_mean_squared_error: 0.9264\n",
      "Epoch 12/100\n",
      "198/250 [======================>.......] - ETA: 0s - loss: 0.8304 - root_mean_squared_error: 0.9037\n",
      "Epoch 12: val_root_mean_squared_error improved from 0.92642 to 0.92546, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8332 - root_mean_squared_error: 0.9053 - val_loss: 0.8695 - val_root_mean_squared_error: 0.9255\n",
      "Epoch 13/100\n",
      "196/250 [======================>.......] - ETA: 0s - loss: 0.8264 - root_mean_squared_error: 0.9013\n",
      "Epoch 13: val_root_mean_squared_error improved from 0.92546 to 0.92451, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8271 - root_mean_squared_error: 0.9016 - val_loss: 0.8682 - val_root_mean_squared_error: 0.9245\n",
      "Epoch 14/100\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 0.8213 - root_mean_squared_error: 0.8981\n",
      "Epoch 14: val_root_mean_squared_error improved from 0.92451 to 0.92388, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8221 - root_mean_squared_error: 0.8986 - val_loss: 0.8675 - val_root_mean_squared_error: 0.9239\n",
      "Epoch 15/100\n",
      "209/250 [========================>.....] - ETA: 0s - loss: 0.8129 - root_mean_squared_error: 0.8933\n",
      "Epoch 15: val_root_mean_squared_error improved from 0.92388 to 0.92229, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.8161 - root_mean_squared_error: 0.8951 - val_loss: 0.8652 - val_root_mean_squared_error: 0.9223\n",
      "Epoch 16/100\n",
      "199/250 [======================>.......] - ETA: 0s - loss: 0.8089 - root_mean_squared_error: 0.8907\n",
      "Epoch 16: val_root_mean_squared_error improved from 0.92229 to 0.92102, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8115 - root_mean_squared_error: 0.8922 - val_loss: 0.8632 - val_root_mean_squared_error: 0.9210\n",
      "Epoch 17/100\n",
      "200/250 [=======================>......] - ETA: 0s - loss: 0.8046 - root_mean_squared_error: 0.8883\n",
      "Epoch 17: val_root_mean_squared_error did not improve from 0.92102\n",
      "250/250 [==============================] - 0s 954us/step - loss: 0.8071 - root_mean_squared_error: 0.8897 - val_loss: 0.8638 - val_root_mean_squared_error: 0.9212\n",
      "Epoch 18/100\n",
      "208/250 [=======================>......] - ETA: 0s - loss: 0.8034 - root_mean_squared_error: 0.8874\n",
      "Epoch 18: val_root_mean_squared_error improved from 0.92102 to 0.92000, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 987us/step - loss: 0.8040 - root_mean_squared_error: 0.8878 - val_loss: 0.8619 - val_root_mean_squared_error: 0.9200\n",
      "Epoch 19/100\n",
      "190/250 [=====================>........] - ETA: 0s - loss: 0.7958 - root_mean_squared_error: 0.8830\n",
      "Epoch 19: val_root_mean_squared_error did not improve from 0.92000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 0.8008 - root_mean_squared_error: 0.8857 - val_loss: 0.8625 - val_root_mean_squared_error: 0.9203\n",
      "Epoch 20/100\n",
      "206/250 [=======================>......] - ETA: 0s - loss: 0.7963 - root_mean_squared_error: 0.8831\n",
      "Epoch 20: val_root_mean_squared_error improved from 0.92000 to 0.91828, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7978 - root_mean_squared_error: 0.8840 - val_loss: 0.8588 - val_root_mean_squared_error: 0.9183\n",
      "Epoch 21/100\n",
      "194/250 [======================>.......] - ETA: 0s - loss: 0.7895 - root_mean_squared_error: 0.8794\n",
      "Epoch 21: val_root_mean_squared_error improved from 0.91828 to 0.91703, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7947 - root_mean_squared_error: 0.8823 - val_loss: 0.8567 - val_root_mean_squared_error: 0.9170\n",
      "Epoch 22/100\n",
      "198/250 [======================>.......] - ETA: 0s - loss: 0.7886 - root_mean_squared_error: 0.8788\n",
      "Epoch 22: val_root_mean_squared_error did not improve from 0.91703\n",
      "250/250 [==============================] - 0s 963us/step - loss: 0.7912 - root_mean_squared_error: 0.8803 - val_loss: 0.8571 - val_root_mean_squared_error: 0.9172\n",
      "Epoch 23/100\n",
      "199/250 [======================>.......] - ETA: 0s - loss: 0.7796 - root_mean_squared_error: 0.8737\n",
      "Epoch 23: val_root_mean_squared_error improved from 0.91703 to 0.91575, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7878 - root_mean_squared_error: 0.8784 - val_loss: 0.8543 - val_root_mean_squared_error: 0.9157\n",
      "Epoch 24/100\n",
      "202/250 [=======================>......] - ETA: 0s - loss: 0.7792 - root_mean_squared_error: 0.8733\n",
      "Epoch 24: val_root_mean_squared_error improved from 0.91575 to 0.91463, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7832 - root_mean_squared_error: 0.8756 - val_loss: 0.8525 - val_root_mean_squared_error: 0.9146\n",
      "Epoch 25/100\n",
      "199/250 [======================>.......] - ETA: 0s - loss: 0.7751 - root_mean_squared_error: 0.8711\n",
      "Epoch 25: val_root_mean_squared_error improved from 0.91463 to 0.91286, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7784 - root_mean_squared_error: 0.8730 - val_loss: 0.8492 - val_root_mean_squared_error: 0.9129\n",
      "Epoch 26/100\n",
      "242/250 [============================>.] - ETA: 0s - loss: 0.7741 - root_mean_squared_error: 0.8704\n",
      "Epoch 26: val_root_mean_squared_error did not improve from 0.91286\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7736 - root_mean_squared_error: 0.8701 - val_loss: 0.8497 - val_root_mean_squared_error: 0.9131\n",
      "Epoch 27/100\n",
      "211/250 [========================>.....] - ETA: 0s - loss: 0.7652 - root_mean_squared_error: 0.8652\n",
      "Epoch 27: val_root_mean_squared_error did not improve from 0.91286\n",
      "250/250 [==============================] - 0s 921us/step - loss: 0.7687 - root_mean_squared_error: 0.8672 - val_loss: 0.8495 - val_root_mean_squared_error: 0.9129\n",
      "Epoch 28/100\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 0.7598 - root_mean_squared_error: 0.8620\n",
      "Epoch 28: val_root_mean_squared_error improved from 0.91286 to 0.91168, saving model to weights1.hdf5\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7636 - root_mean_squared_error: 0.8642 - val_loss: 0.8477 - val_root_mean_squared_error: 0.9117\n",
      "Epoch 29/100\n",
      "200/250 [=======================>......] - ETA: 0s - loss: 0.7565 - root_mean_squared_error: 0.8598\n",
      "Epoch 29: val_root_mean_squared_error did not improve from 0.91168\n",
      "250/250 [==============================] - 0s 961us/step - loss: 0.7590 - root_mean_squared_error: 0.8612 - val_loss: 0.8485 - val_root_mean_squared_error: 0.9119\n",
      "Epoch 30/100\n",
      "209/250 [========================>.....] - ETA: 0s - loss: 0.7509 - root_mean_squared_error: 0.8564\n",
      "Epoch 30: val_root_mean_squared_error did not improve from 0.91168\n",
      "250/250 [==============================] - 0s 926us/step - loss: 0.7549 - root_mean_squared_error: 0.8586 - val_loss: 0.8531 - val_root_mean_squared_error: 0.9143\n",
      "Epoch 31/100\n",
      "213/250 [========================>.....] - ETA: 0s - loss: 0.7490 - root_mean_squared_error: 0.8550\n",
      "Epoch 31: val_root_mean_squared_error did not improve from 0.91168\n",
      "250/250 [==============================] - 0s 924us/step - loss: 0.7515 - root_mean_squared_error: 0.8564 - val_loss: 0.8502 - val_root_mean_squared_error: 0.9125\n",
      "Epoch 32/100\n",
      "206/250 [=======================>......] - ETA: 0s - loss: 0.7451 - root_mean_squared_error: 0.8526\n",
      "Epoch 32: val_root_mean_squared_error did not improve from 0.91168\n",
      "250/250 [==============================] - 0s 939us/step - loss: 0.7474 - root_mean_squared_error: 0.8540 - val_loss: 0.8539 - val_root_mean_squared_error: 0.9143\n",
      "Epoch 33/100\n",
      "206/250 [=======================>......] - ETA: 0s - loss: 0.7403 - root_mean_squared_error: 0.8495\n",
      "Epoch 33: val_root_mean_squared_error did not improve from 0.91168\n",
      "250/250 [==============================] - 0s 993us/step - loss: 0.7439 - root_mean_squared_error: 0.8515 - val_loss: 0.8563 - val_root_mean_squared_error: 0.9155\n"
     ]
    }
   ],
   "source": [
    "batch_size = 320\n",
    "epochs = 100\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "history = model.fit([ratings_train.user_id, ratings_train.movie_id], \n",
    "                    ratings_train.rating, \n",
    "                    validation_data=([ratings_val.user_id, ratings_val.movie_id], ratings_val.rating), \n",
    "                    batch_size = batch_size,\n",
    "                    callbacks = [checkpointer, early_stopping],\n",
    "                    epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in history.history.items():\n",
    "  mlflow.log_metric(key, value[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 617us/step - loss: 0.8477 - root_mean_squared_error: 0.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8476566672325134, 0.9037073254585266]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([ratings_val.user_id, ratings_val.movie_id], ratings_val.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 630us/step - loss: 0.8477 - root_mean_squared_error: 0.9037\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('weights1.hdf5')\n",
    "mse, rmse = model.evaluate([ratings_val.user_id, ratings_val.movie_id], ratings_val.rating)\n",
    "mlflow.log_metric(\"val_mse\", mse) \n",
    "mlflow.log_metric(\"val_rmse\", rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Movie-Embedding', 'User-Embedding')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embeddings_layer = model.layers[2]\n",
    "user_embeddings_layer = model.layers[3]\n",
    "\n",
    "movie_embeddings_layer.name, user_embeddings_layer.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 17:28:49 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) User, Item with unsupported characters which will be renamed to user, item in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/7f/19f36bv57_72qpq3mfj1x6240000gn/T/tmpx15stbtv/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/7f/19f36bv57_72qpq3mfj1x6240000gn/T/tmpx15stbtv/model/data/model/assets\n",
      "2024/11/17 17:28:54 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/7f/19f36bv57_72qpq3mfj1x6240000gn/T/tmpx15stbtv/model, flavor: tensorflow). Fall back to return ['tensorflow==2.11.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/11/17 17:28:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x1884bbac0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.keras.log_model(model, \"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 17:28:57 INFO mlflow.tracking._tracking_service.client: 🏃 View run Early Stoping + latent factor 5 (3) at: http://127.0.0.1:5001/#/experiments/981061820529434616/runs/4b88bd999cfa4d8e806b18d75ba56761.\n",
      "2024/11/17 17:28:57 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5001/#/experiments/981061820529434616.\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hay una diferencia de 1 entre n_movies, n_users y  el shape de las matrices de embeddigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1683, 5), (944, 5), 1682, 943)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embeddings_matrix = movie_embeddings_layer.get_weights()[0]\n",
    "user_embeddings_matrix = user_embeddings_layer.get_weights()[0]\n",
    "\n",
    "movie_embeddings_matrix.shape, user_embeddings_matrix.shape, n_movies, n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('../data/vector_db/movie_embeddings_matrix_1.npy', movie_embeddings_matrix)\n",
    "np.save('../data/vector_db/user_embeddings_matrix_1.npy', user_embeddings_matrix)\n",
    "np.save('../data/vector_db/user2Idx_1.npy', user2Idx)\n",
    "np.save('../data/vector_db/movie2Idx_1.npy', movie2Idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
